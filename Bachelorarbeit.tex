\documentclass[a4paper,12pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage[pdftex]{hyperref}
\usepackage{floatflt}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{xcolor}
\usepackage{framed}
\usepackage{changes}
\usepackage{tikz}
\usepackage{capt-of}
\usepackage{diagbox}
\usetikzlibrary{arrows.meta}
\usepackage[thmmarks, thref]{ntheorem}
\usepackage{amsmath, amssymb}
%\usepackage[amsmath, thmmarks, thref]{ntheorem}
\usepackage{verbatim}
\usepackage{fancyhdr}
\usepackage[hang]{footmisc}
\renewcommand{\subsectionmark}[\thepage]{\markright{{#1}}}
\textheight220mm
\headheight 28pt
\textwidth160mm
\oddsidemargin0mm
\evensidemargin0mm
\topmargin0mm
\pagestyle{headings}
\fancyhead[R]{\sectionmark}
\newcommand{\F}{\mathbb F}
\newcommand{\f}{\mathbb f}
\newcommand{\K}{\mathbb K}
\newcommand{\R}{\mathcal R}
\newcommand{\N}{\mathbb N}
\newcommand{\Z}{\mathbb Z}
\newcommand{\Q}{\mathbb Q}
\newcommand{\A}{\mathcal A}
\newcommand{\C}{\mathcal C}
\newcommand{\D}{\mathcal D}
\newcommand{\X}{\mathcal X}
\newcommand{\Y}{\mathcal Y}
\newcommand{\xL}{\mathcal L}
\newcommand{\xP}{\mathcal P}
\newcounter{Hilfssatz}
\newcounter{Definition}
\newcounter{Beispiel}
\newcounter{Satz}
\newcounter{Algorithmus}



\setlength{\parindent}{0pt}
\makeatletter
  \@addtoreset{Definition}{subsection}
\makeatother
\newenvironment{Definition}{
\bigskip
        
        \setlength{\parindent}{0pt}
        \addtocounter{Definition}{1}
        \textbf{\textsf{Definition \thesubsection.\theDefinition}:}\\}{
        \nopagebreak
        \vspace{-1.0ex}
        \bigskip
        
}
\makeatletter
  \@addtoreset{Hilfssatz}{subsection}
\makeatother
\newenvironment{Hilfssatz}{
\medskip
        
        \setlength{\parindent}{0pt}
        \addtocounter{Hilfssatz}{1}
        \textbf{\textsf{Hilfssatz \thesubsection.\theHilfssatz}:}\\}{
        \nopagebreak
        \vspace{-1.0ex}
        \bigskip\\
}

\makeatletter
  \@addtoreset{Satz}{subsection}
\makeatother
\newenvironment{Satz}{
\medskip
        
        \setlength{\parindent}{0pt}
        \addtocounter{Satz}{1}
        \textbf{\textsf{Satz \thesubsection.\theSatz}:}\\}{
        \nopagebreak
        \vspace{-1.0ex}
        \bigskip\\
        
}

\makeatletter
  \@addtoreset{Beispiel}{subsection}
\makeatother
\newenvironment{Beispiel}{
\medskip
        
        \setlength{\parindent}{0pt}
        \addtocounter{Beispiel}{1}
        \textbf{\textsf{Beispiel \thesubsection.\theBeispiel}:}\\}{
        \nopagebreak
        \vspace{-1.0ex}
        \bigskip
        
}

\setlength{\parindent}{0pt}
\newenvironment{proof}{
%\bigskip
        \setlength{\parindent}{0pt}
        \textbf{Beweis:}\\}{
        \nopagebreak
        \vspace{-1.0ex}
        \begin{flushright}
             $\square$
        \end{flushright}
        \bigskip
        
}

\makeatletter
  \@addtoreset{Algorithmus}{subsection}
\makeatother
\newenvironment{Algorithmus}{
\medskip
        
        \setlength{\parindent}{0pt}
        \addtocounter{Algorithmus}{1}
        \textbf{\textsf{Algorithmus \thesubsection.\theAlgorithmus}:}}{
        \nopagebreak
        \vspace{-1.0ex}
        \bigskip
        
}

\usepackage{lastpage}% F\"ur die Verweise innerhalb des  Symbolverzeichnisses

\usepackage{nomencl} % Symbolverzeichnis
\let\symb\nomenclature %% Es genuegt \symb statt \nomenclature zu  schreiben
\setlength{\nomlabelwidth}{.25\hsize}
\renewcommand{\nomlabel}[1]{#1 \dotfill}
\setlength{\nomitemsep}{-\parsep}\renewcommand{\nomname}
{Symbolverzeichnis}

\setlength{\nomitemsep}{-\parsep}
\usepackage{array} %notwendig um neue Spaltentypen zu definieren
\newcolumntype{B}[1]{>{\centering\arraybackslash}m{#1}}
\makenomenclature

\newcommand{\CC}{C\nolinebreak\hspace{-.05em}\raisebox{.4ex}{\tiny\bf+}\nolinebreak\hspace{-.10em}\raisebox{.4ex}{\tiny\bf+}\;}
\begin{document}
\begin{titlepage}
\thispagestyle{empty} \enlargethispage{1.4in}

\begin{center}

\rule[1ex]{157.5mm}{0.5mm}

\LARGE\bf Hochschule für angewandte Wissenschaften Coburg\\

\vfill

\rm Institut für Informatik


\begin{figure}
	    \centering
				     \includegraphics[width=0.5\textwidth]{Logo.png}
\end{figure}

\vfill

\Huge \bf Asymmetrische Zahlensysteme

\vfill

\Large Bachelorarbeit \\ [1ex] von \\ [1ex]
Dipl.-Math. Michael Krasser

\vfill

Betreuer:  Prof.\,Dr.~Quirin~Meyer

\vfill

Coburg, \today

\rule[-1ex]{157.5mm}{0.5mm}

\vfill

\end{center}

\end{titlepage}
\newpage
\section*{Vorwort}
Diese Arbeit entstand während des Wintersemesters 18/19. Für die Anregung und Ermutigung mich mit diesem Thema auseinanderzusetzen möchte ich Herrn Prof. Dr. Quirin Meyer meinen besonderen Dank aussprechen.
\par
\vspace{5mm}
\par
Insbesondere möchte ich mich bei meiner Freundin Julia Isabel Schmidt und meinen Eltern, Dr. Walter und Cornelia Krasser für ihre Unterstützung während meines Studiums bedanken.
\pagebreak
\newpage
\begin{center}
	die meißten menschen
	\\
	glauben an niederlagen.
	\\
	sie siegen nie und glauben,
	\\
	die welt habe also recht.
	\\
	wie albern.\footnote{ronald m. schernikau "`legende"'}
\end{center}

\newpage
\tableofcontents
\pagebreak
\section{Einleitung}
Im Zeitalter der Digitalisierung werden immer größere Datenmengen produziert, gespeichert und übertragen, was sowohl den Einsatz als auch die Suche nach effizienten Verfahren zur Datenkom{\tt{pre}}ssion unerläßlich macht.
Hierfür schlägt Jaroslaw Duda\cite{Duda} ein neues Verfahren mit dem Namen "`asymmetrische Zahlensysteme"' vor, das seitdem von Unternehmen wie Facebook\cite{fb}, Google\cite{google} und Apple\cite{apple} verwendet wird. 
\par
Im Rahmen dieser Bachelorarbeit über asymmetrische Zahlensysteme sollen zunächst grundlegende Begriffe aus dem Bereich der Codierungstheorie geklärt und gänge Entropiecodierer besprochen werden.
Anschließend sollen die in \cite{Giesen}, \cite{Duda} und \cite{Krajcevski} angegebene Verfahren {\tt{uabs}} und {\tt{rans}} untersucht werden.
\par
\vspace{0.5cm}
Ziel dieser Arbeit ist eine eigenständige Verallgemeinerung des {\tt{uabs}}-Verfahrens auf $n$-elementige Symbolalphabete ({\tt{uans}}-Verfahren) und die Anwendung des  {\tt{uans}}- sowie des {\tt{rans}}-Verfahrens auf Bilddateien. Zusätzlich soll der Einfluss einer vorgeschalteten Filterung -- die in Kapitel ~\ref{Filter} besprochen wird -- untersucht werden. Hierfür werden die verwendeten Filter und die beiden Verfahren in \CC implementiert\footnote{Unter \url{https://github.com/Hau-Bold/ANS_Java} befindet sich eine Umsetzung der Verfahren in Java (Swing)}. 
\par
\vspace{0.5cm}
Nachfolgende Abbildung veranschaulicht den Programmfluss:

\begin{center}
{\color{gray!50!blue}\rule{9cm}{0.1mm}}
\vspace{0.2cm}
\\
\begin{tabular}{c c}
initialer Zustand & schreiben beendet 
\\
{\tt{readImage}} & {\tt{writeImage}}
\\
$\downarrow$ & $\uparrow$ 
\\
{\tt{normalize}} & 
\\
$\downarrow$ & 
\\
{\tt{execute{\tt{pre}}condition}} & {\tt{execute{\tt{post}}condition}}
\\
$\downarrow$ & $\uparrow$ 
\\
{\tt{encode}} & {\tt{decode}}
\\
$\downarrow$ & $\uparrow$ 
\\
{\tt{writeBinaryFile}} & {\tt{readBinaryFile}}
\\
$\downarrow$ & $\uparrow$ 
\\
finaler Zustand & finaler Zustand
\end{tabular}
{\color{gray!50!red}\rule{9cm}{0.1mm}}
\vspace{0.5cm}
\captionof{figure}{Programmfluss der Implementierung}
\end{center}
In Leserichtung wird das Bild gelesen, vorkonditionert, normalisiert und 
anschließend komprimiert.
Die Dekomprimierung erfolgt in umgekehrter Leserichtung. 
\par
In Kapitel ~\ref{Kommandozeilenparameter} findet sich eine Anleitung zur Konfiguration der \CC Implementierung.
\newpage
\section{Kompression und Dekompression}
Dieser Abschnitt orientiert sich an\cite{henne} sowie \cite{Lajmi} und klärt die wichtigsten Begriffe aus dem Bereich Datenkompression und stellt gängige Entropiecodierer vor.
\subsection{Grundlagen}
\begin{Definition}
Unter Datenkompression versteht man ein Paar $(\X,\Y)$ von Algorithmen - Datenkompressionschema genannt, mit folgenden Eigenschaften:

Der Algorithmus $\X \; \left(Kompression\right)$ konstruiert für die Eingabe $X$ eine Repräsentation $X_c$, die (möglichst) weniger Bits als $X$ benötig.
\par
Der Algorithmus  $\Y \; \left(Dekompression\right)$ generiert zu gegebenem $X_c$ die Rekonstruktion $Y$.
\par
 Ein Datenkompressionschema heißt verlustfrei, wenn $X = Y$, ansonsten verlustbehaftet.
\end{Definition}
Desweiteren definiert man zur Beurteilung der Qualität eines Komprimierungsschemas:
\begin{Definition}
Sei $\mu_c$ die Anzahl der Bits von $X_c$ und $\mu$ die Anzahl der Bits von $X$. Dann heißt der durch
$
\mu_c \slash \mu
$
definierte Ausdruck Kompressionsquotient\footnote{\footnotesize{Der Kehrwert des Kompressionsquotienten wird auch Kompressionsfaktor genannt.}}.
\end{Definition}
\subsection{Über die Möglichkeit der Datenkompression}
 Vesteht man unter Datenkompression ein Verfahren, das eine bestimmte Repräsentation in eine andere überführt, die stets weniger Bits als die urspüngliche benötigt, dann zeigt ein einfaches Abzählargument, dass es ein solches Verfahren nicht geben kann. Diese Argumentation wird in Arbeiten zum Thema Kolmogorov-Komplexität als sog. Inkompressibilitätsargument bezeichnet und begründet, warum sich bestimmte Bitfolgen nicht komprimieren lassen: Die Kolmogorov-Komplexität einer Bitfolge $t$ ist definiert als die Länge des kürzesten "`Programms"', welches $t$ erzeugt\footnote{\footnotesize{Bei geeigneter Formalisierung des Begriffs
"`Programm"' ist die Kolmogorov-Komplexität bis auf eine additive Konstante wohldefiniert.\cite{Li} }}. Eine Bitfolge heißt unkomprimierbar, falls sie selbst ihre kürzeste Beschreibung ist.
Trotzdem funktioniert die Datenkompression in der Praxis hervorragend:
\begin{itemize}
	\item Einzelne Zeichen (Grundelemente des Alphabets) tauchen nicht mit der selben Wahrscheinlichkeit auf. $\Rightarrow$ 
verschlüssele wahrscheinlichere Zeichen mit weniger Bit als unwahrscheinlichere (Morse-Alphabet).
\item Blöcke von Zeichen lassen sich aufgrund der Abhängigkeiten aufeinander folgender Ereignisse geschickter gemeinsam als lose unabhängige Folge einzelner Zeichen verschlüsseln.  
\item Information ist nicht zufällig, sondern enthält  zahllose Regelmäßigkeiten.
\par
 Eine Grundstrategie von Kompressionsverfahren beruht darauf, solche Regeln zu entdecken (z.B. Wörterbuchtechniken).
\item  Für oder von Menschen erzeugte Information ist nicht zusammenhangslos. Vielfach ist es möglich, verschiedene Gattungen von Information zu unterscheiden: Sei z.B. bekannt, dass die vorliegende Bitfolge einen ASCII-Text der englischen Sprache darstellt, so muss ein anderes Kompressionsverfahren (auf Byte-Ebene) die Bitfolge der zeilenweisen Darstellung eines Schwarz-Weiß-Bildes repräsentieren (starke Abhängigkeiten von Bit zu Bit, zeilen- und spaltenweise).
\item Oft kann auf eine exakte Rekonstruierbarkeit des Originals verzichtet werden da gewisse Feinheiten von menschlichem Auge oder Ohr nicht wahrgenommen werden:  Frequenzen von Audiodaten, die für das menschliche Ohr gedacht sind und nicht wahrgenommen werden, können, von vornherein vernachlässigt werden.
\end{itemize}
\subsection{Entropiekodierer}
\subsubsection{Die Entropie}
\begin{Definition}
Gegeben sei eine diskrete Quelle $Q$ mit den Symbolen $x_{1},\ldots,x_{N}$ und dazugehörigen Wahrscheinlichkeiten $p_1,\ldots,p_N$.
\par
Bezeichne $I(x_{i}) = -\text{log}_{2}(p_{i})$ den Informationsgehalt des Symbols $x_{i}$.
Die Entropie (mittlere Informationsgehalt) von $Q$ ist definiert durch
\begin{align*}
H(Q):=\sum_{i=1}^N p(x_{i})\cdot I(x_{i}) =- \sum_{i=1}^N p(x_{i}) \cdot \text{log}_2(p(x_{i})).
\end{align*}
Die Entropie von $Q$ heißt maximal, wenn $H(Q) = \text{log}_2(N)$.
 Diese maximale Entropie wird mit $H_{0}$ bezeichnet und heißt Entscheidungsgehalt.
\end{Definition}
\begin{Definition}
Entropiekodierung bezeichnet ein Verfahren, welches die Entropie einer Nachricht optimiert, d. h., der maximalen Entropie annähert.
\end{Definition}
Abschließend definieren wir den Begriff der  {\it Redundanz und der erwarteten Länge} eines Codes:
\begin{Definition}
Sei $\Sigma = \{a_{1},\ldots, a_{k}\}$ ein Alphabet mit zugehörigen Auftrittswahrscheinlichkeiten 
$$
\{P(a_{i})\,|\,i=1,\ldots,k\}.
$$
Die Kodierung $\mathcal{K}: \Sigma\rightarrow \{0, 1\}^{\N}$ besitzt die erwartete Länge
$
L(\mathcal{K}):=\sum_{i=1}^{k} P(a_{i})\cdot \left| \mathcal{K}(a_{i})\right|.
$
Der Term 
\begin{align*}
r:=L(\mathcal{K}) - H(\Sigma)
\end{align*}
bezeichnet die Redundanz der Kodierung.
\end{Definition}
\subsubsection{Kom{\tt{pre}}ssion nach dem Verfahren von Shannon}
Nach Shannon gilt:
\begin{Satz}
Für Jede Quelle $Q$ und jede beliebige zugehörige Binärcodierung mit 
Präfix-Eigenschaft ist die zugehörige mittlere Codewortlänge $L$ 
nicht kleiner als die Entropie $H(Q)$:
\begin{align*}
 H(Q)\leq L
\end{align*}
\end{Satz}
\begin{proof}
Siehe \cite{Rohling}.
\end{proof}
Um für einen gegebenen Text einen dekodierbaren Code mit minimaler Länge zu finden, geht man nach Shannon folgendermaßen vor:
\begin{itemize}
	\item[1)]  Sortiere zu kodierende Symbole $x_{1},\ldots,x_{N}$ nach fallender Auftrittswahrscheinlichkeit: 
$p_{1}\geq p_{2}\geq\ldots\geq p_{N}$.
	\item[2)] Bestimme für $1\leq i \leq N$ die Codewortlänge $\mathcal{K}(x_{i}) = \lfloor -\text{log}_2(p(x_{i}))\rfloor$ jedes Zeichens aus seinem Informationsgehalt.
	\item[3)] Berechne für $1\leq i \leq N$ die kumulierten Wahrscheinlichkeiten $P(x_{i}):=\sum_{l=0}^{i-1}p(x_{l})$.
	\item[4)] Die Codierung jedes Zeichens $x_{i}$ ergibt sich dann aus den ersten $\mathcal{K}(x_{i})$ Zeichen der Mantisse der Binärdarstellung von $P(x_{i})$.
\end{itemize}
\begin{Beispiel}

\begin{center}
\begin{tabular}{c|c|c|c|c|c}
$x_{i}$ & $p(x_{i})$ & $\mathcal{K}(x_{i})$ & $P(x_{i})$ & binär & Code
\\
\hline
a & 0.3 & 2 & 0 & $0.000\ldots$ & 00
\\
\hline
b & 0.3  & 2 & 0.3 & 0.0100\ldots & 01
\\
\hline
c & 0.2  & 3 & 0.6 & 0.1001\ldots & 100
\\
\hline
d & 0.1  & 4 & 0.8 & 0.1100\ldots & 1100
\\
\hline
e & 0.1  & 4 & 0.9 & 0.1110\ldots & 1110
\end{tabular}
\end{center}
\end{Beispiel}
Dieses Verfahren ist eines der ersten zur Erstellung von präfixfreien, längenvariablen Codes.
\subsubsection{Kom{\tt{pre}}ssion nach dem Verfahren von Fano}
Ein weiteres Beispiel für einen Präfixcode ist die Shannon-Fano Codierung:
\begin{itemize}
\item[1)] Sortiere zu kodierende Symbole $x_{1},\ldots,x_{N}$ nach fallender Auftrittswahrscheinlichkeit: 
$p_{1}\geq p_{2}\geq\ldots\geq p_{N}$
\item[2)] Teile Menge der Symbole in zwei Teilmengen mit möglichst gleicher Wahrscheinlichkeit.
\item[3)] Kodiere linke Teilmenge mit null, die rechte mit eins.
\item[4)] Sind entstandene Teilmengen nicht einelementig, gehe zu Schritt 2.
\end{itemize}
\begin{Beispiel}
\begin{minipage}[h]{.7\textwidth}
Gegeben sei das vierelementige Alphabet $\left\{A, B, C, D\right\}$ mit 
\par
 zugehörigen Auftrittswahrscheinlichkeiten
\begin{center}
 $p_A =0.4,\, p_B = 0.3,\, p_C = 0.2,\, p_D =0.1$.
\end{center}
\qquad\qquad$\Rightarrow$ $A=0,\,B=111,\,C=110,\,D=10$
\\
\vspace{0.2cm}
\end{minipage}
\hfill
 \begin{minipage}[h]{.2\textwidth}
\begin{flushright}
$\underbrace{A}_{0} \;\underbrace{D\; C\; B\;}_{1}$
\\
\quad$\underbrace{D}_{0}\;\underbrace{C\; B\;}_{1}$
\\
\quad\quad$\underbrace{C}_{0}\;\underbrace{B}_{1}$
\end{flushright}
\end{minipage}    
\end{Beispiel}
\subsubsection{Huffman-Algorithmus}
Um einen Code auch wieder eindeutig dekodieren zu können, muss er die Kraftsche Ungleichung erfüllen und zusätzlich noch präfixfrei sein, d. h. kein Codewort darf der Beginn eines anderen sein.
Die Huffman-Kodierung ist eine Form der Entropiekodierung, die 1952 von David A. Huffman entwickelt und in \cite{Huffman} publiziert wurde.
Die Kodierung ist ein Präfix-Code (also ein Code mit kleinster erwarteter Länge), der einer festen Anzahl von Quellsymbolen Codewörter mit variabler Länge zuordnet.
\begin{Algorithmus} (Huffmann-Kodierung)
\\
 Sei $\A$ ein Symbolalphabet, $p_{x}=p(x)$ die relative Häufigkeit des Symbols $x \in \A$, $\C$ das Codealphabet und $m=| \C |$ die Mächtigkeit von $\C$.
\par
\textbf{Aufbau des Baumes}
\begin{itemize}
	\item[1)] Erstelle für $x \in \A$ einen Knoten mit zugehöriger Häufigkeit.
	\item Wiederhole folgende Schritte, bis nur noch ein Baum übrig ist:
	\begin{itemize}
		\item[i)] Wähle die $m$ Teilbäume mit der geringsten Häufigkeit in der Wurzel, bei mehreren Möglichkeiten die Teilbäume mit der geringsten Tiefe.
		\item[ii)]  Fasse diese Bäume zu einem neuen (Teil-)Baum zusammen.
		\item[iii)]  Notiere die Summe der Häufigkeiten in der Wurzel.
	\end{itemize} 
\end{itemize}
\newpage
\textbf{Konstruktion des Codebuchs}
\begin{itemize}
	\item[1)]  Jedem Kind eines Knotens wird eindeutig ein Zeichen aus dem Codealphabet zuzugehordnet.
	\item[2)]  Für jedes Quellsymbol wird das Codewort ausgelesen: Beginne an der Wurzel des Baums. Die Codezeichen auf den Kanten des Pfades (in dieser Reihenfolge) ergeben das zugehörige Codewort.
\end{itemize}   
\end{Algorithmus}
\begin{Beispiel}
Die Nachricht {\it aababcabcd} soll auf Basis des Codealphabets $\C=\{0,1\}$ kodiert werden. Zunächst erhält man
\begin{align*}
 \A = \{a, b, c, d\}\quad \text{mit}\quad
\begin{tabular}{c|c|c|c|c}
X & a & b & c & d
\\
\hline
P(X) & 0.4 & 0.3 & 0.2 & 0.1
\\
\end{tabular} 
\end{align*}
\textbf{Konstruktion des Huffman-Baums:}
\par
\vspace{0.5cm}
\begin{align*}
\begin{tikzpicture}
 \draw(0.0,-0.75)node[]{a}
		(0.75,-0.75)node[circle=0.3cm,fill = gray]{0.4}
		 (1.0,-1.0) -- (1.5,-1.5)
		(1.75,-1.75) node [circle=0.3cm,fill = gray]{0.3}
		(0.75,-1.75) node []{b}
		(2.0,-2.0) -- (2.5,-2.5);
		\draw[->, blue!50, very thick] (4.5,-2.75) to[bend left=20]
 (5.5,-2.75);
		\draw
		(2.75,-2.75) node [circle=0.3cm, fill=red]{0.2}
		(1.5,-2.75) node []{c}
			(3.0,-3.0) -- (3.5,-3.5)
			(3.75,-3.75) node [circle=0.3cm, fill=red]{0.1}
			(2.25,-3.75) node []{d}
			%Ende 1
	(5.0,-0.75)node[]{a}
	(5.75,-0.75) node [circle=0.3cm,fill = gray]{0.4}
  (6.0,-1.0) -- (6.5,-1.5)
	(6.0,-1.75)node[]{b}
	(6.75,-1.75) node [circle=0.3cm,fill = gray]{0.3}
(7.0,-2.0) -- (7.5,-2.5)
(7.75,-2.75) node [circle=0.3cm]{0.3}
		(7.75,-3.0) -- (7.25,-3.5)
		(7.0,-4.5)node[]{c}
		(7.0,-3.75) node [circle=0.3cm, fill=red]{0.2};
		\draw[->, blue!50, very thick] (8.5,-2.75) to[bend left=20]
 (9.5,-2.75);
		\draw
		(7.75,-3.0) -- (8.25,-3.5)
		(8.5,-4.5)node[]{d}
		(8.5,-3.75) node [circle=0.3cm, fill=red]{0.1}
		%Ende 2
	(10.75,-0.75) node []{1.0}
	(11.0,-1.0) -- (11.0,-5.0)
  (11.0,-1.0) -- (12.0,-2.0)
	(12.25,-2.25) node []{0.6}
	(12.25,-2.5) -- (12.25,-5.0)
	(12.5,-2.5) -- (13.5,-3.5)
	(13.75,-3.75) node []{0.3}
	(14.0,-4.0) -- (15.0,-5.0)
	(14.0,-4.0) -- (14.0,-5.0)
	(15.25,-5.25) node [circle=0.3cm, fill=red]{0.1}
	(15.25,-6.0)node[]{d}
	(14.0,-5.25) node [circle=0.3cm, fill=red]{0.2}
	(14.0,-6.0)node[]{c}
	(12.25,-5.25) node [circle=0.3cm, fill=red]{0.3}
	(12.25,-6.0)node[]{b}
	(10.75,-5.25) node [circle=0.3cm, fill=red]{0.4}
	(10.75,-6.0)node[]{a};
\end{tikzpicture}
\end{align*}
\textbf{Konstruktion des Codebuchs:}
\par
Jeder linke Zweig wird mit einer eins, jeder rechte mit einer null versehen:
\par
\vspace{0.5cm}
\begin{minipage}[h]{.4\textwidth}
\begin{tabular}{c|c}
Symbol & Verschlüsselung
\\
\hline
a & 1
\\
\hline
b & 01
\\
\hline
c & 001
\\
\hline
d & 000
\end{tabular}
\vspace{3cm}
\end{minipage}
\hfill
 \begin{minipage}[h]{.6\textwidth}
\begin{tikzpicture}
\draw
(0.75,-0.75) node []{1.0}
  (0.7,-2.5) node []{1}
	(1.0,-1.0) -- (1.0,-5.0)
	(1.8,-1.5) node []{0}
  (1.0,-1.0) -- (2.0,-2.0)
	(2.25,-2.25) node []{0.6}
	(1.9,-3.75) node []{1}
	(2.25,-2.5) -- (2.25,-5.0)
	(3.3,-3.0) node []{0}
	(2.5,-2.5) -- (3.5,-3.5)
	(3.75,-3.75) node []{0.3}
	(4.8,-4.5) node []{0}
	(4.0,-4.0) -- (5.0,-5.0)
	(3.7,-4.5) node []{1}
	(4.0,-4.0) -- (4.0,-5.0)
	(5.25,-5.25) node [circle=0.3cm, fill=red]{0.1}
	(5.25,-6.0)node[]{d}
	(4.0,-5.25) node [circle=0.3cm, fill=red]{0.2}
	(4.0,-6.0)node[]{c}
	(2.25,-5.25) node [circle=0.3cm, fill=red]{0.3}
	(2.25,-6.0)node[]{b}
	(0.75,-5.25) node [circle=0.3cm, fill=red]{0.4}
	(0.75,-6.0)node[]{a};
\end{tikzpicture}
\hspace{1.5cm} 
\end{minipage} 
Damit kodiert sich die Nachricht {\it a 	a 	b 	a 	b 	c 	a 	b 	c 	d} zu
$1\, 	1\, 	01\, 	1\, 	01\, 	001\, 	1\, 	01\, 	001\, 	000$.\footnote{\footnotesize{Bei der Dekodierung verfolgt man ausgehend von der Wurzel den entsprechende Pfad im Baum bis man an einem Blatt ankommt.}} 
\par  
In diesem Fall erhält man für die Entropie und die erwartete Länge:
\begin{align*}
H(Q) &=-\left(  0.4 * \text{log}_{2}(0.4)   +   0.3 * \text{log}_{2}(0.3) +  0.2 * \text{log}_{2}(0.2)\right.\\
     &\left.\quad +  0.1 * \text{log}_{2}(0.1)\right) = 1.84643934467
\\
L(\mathcal{K})&= 0.4 + 2\cdot 0.3 + 3* 0.3 = 1.9,
\end{align*}
d.h bei einer zu kodierenden Nachricht von 1000000 Symbolen sind etwa 28190 Symbole redundant.
\end{Beispiel}
\subsubsection{Erweiterte Huffman-Codierung}
Wir betrachten einführend folgendes Beispiel: Sei $\Sigma = \{a, b\}$ mit $p(a)=0.9,\,p(b)=0.1$. Dann liefert die Huffman-Kodierung
\begin{center}
\begin{tabular}{c|c|c}
 & p & Code
\\
\hline
a & 0.9 & 1
\\
\hline
b & 0.1 & 0
\end{tabular}
\end{center}
mit erwarteter Länge $1$ Bits / Symbol und Entropie $H(\Sigma)=0.47$. Die Redundanz $r=0.53$ beträgt also $113\%$ der Entropie, d.h das der Code nicht komprimiert ist.
Wir betrachten statt dessen das Alphabet
\begin{align*}
\Sigma^{2}:= \{aa,ab,ba,bb\}
\end{align*}
mit $p(aa)=\left(p(a)\right)^{2}$, $p(bb)=\left(p(b)\right)^{2}$ und $p(ab)= p(ba) =p(a)\cdot p(b)$. Die Huffman-Kodierung liefert dann
\par
\hspace{1.5cm}
\begin{minipage}[h]{.5\textwidth}
\begin{tabular}{c|c|c}
Symbol & p & Verschlüsselung
\\
\hline
aa & 0.81 & 1
\\
\hline
ab & 0.09 & 01
\\
\hline
ba & 0.09 & 001
\\
\hline
bb & 0.01 & 000
\end{tabular}
\\
$H(\Sigma^{2})= 0.937991187$ Bits / Symbol
\\
$L(\mathcal(K)) = 1.29$ Bits / Symbol
\end{minipage}
\hfill
 \begin{minipage}[h]{.5\textwidth}
\begin{flushright}
\begin{tikzpicture}
\draw
(0.75,-0.75) node []{1.0}
  (0.7,-2.5) node []{1}
	(1.0,-1.0) -- (1.0,-5.0)
	(1.8,-1.5) node []{0}
  (1.0,-1.0) -- (2.0,-2.0)
	(2.25,-2.25) node []{0.19}
	(1.9,-3.75) node []{1}
	(2.25,-2.5) -- (2.25,-5.0)
	(3.3,-3.0) node []{0}
	(2.5,-2.5) -- (3.5,-3.5)
	(3.75,-3.75) node []{0.1}
	(4.8,-4.5) node []{0}
	(4.0,-4.0) -- (5.0,-5.0)
	(3.7,-4.5) node []{1}
	(4.0,-4.0) -- (4.0,-5.0)
	(5.25,-5.25) node [circle=0.3cm, fill=red]{0.01}
	(5.25,-6.0)node[]{bb}
	(4.0,-5.25) node [circle=0.3cm, fill=red]{0.09}
	(4.0,-6.0)node[]{ba}
	(2.25,-5.25) node [circle=0.3cm, fill=red]{0.09}
	(2.25,-6.0)node[]{ab}
	(0.75,-5.25) node [circle=0.3cm, fill=red]{0.81}
	(0.75,-6.0)node[]{aa};
\end{tikzpicture}
\end{flushright}
\hspace{1.5cm} 
\end{minipage} 
benutzt also nur noch $37\%$ mehr als eine minimale Kodierung.
Hierfür gilt folgender Sachverhalt:
\begin{Hilfssatz}
Für jedes Quellalphabet $\Sigma$ gilt
\begin{align*}
H(\Sigma)\leq L(H^m) \leq H(\Sigma) + \frac{1}{m}.
\end{align*}
\end{Hilfssatz}
Die Anfertigung der Statistiken für jedes Symbol ist praktisch kaum machbar. Abhilfe liefert das nächste Unterkapitel.
\subsubsection{Arithmetisches Kodieren}
Der letztes Unterabschnitt zeigte, dass die erweiterte Huffman-Kodierung eine Ausgabe mit sehr kleiner Redundanz produziert. Die Idee war die Folgende: Statt einzelne Symbole des Quellenalphabets wird die Folge der Symbole mit Hilfe des Huffman-Algorithmus codiert. Der Nachteil des Verfahrens ist aber, dass der Algorithmus Huffman-Codes für alle möglichen Folgen der Quellensymbole konstruieren muss um einen Eingabetext zu codieren. Das heißt beispielsweise, dass für ein Quellenalphabet mit 256 Symbolen und für Folgen der Länge 3 der Algorithmus 16 777 216 neue Symbole betrachten muss. In diesem Kapitel betrachten wir  arithmetische Codes: Statt einzelner Symbole werden Folgen von Symbolen codiert. Der Vorteil des Verfahrens ist dabei, dass jede Folge separat codiert werden kann. Das Schema des Verfahrens ist folgendes: Sei u1u2u3u4 $\in\Sigma$ ein Text. Berechne für die Folge eine numerische Repräsentation – einen Bruch zwischen 0 und 1, und für diese Repräsentation den binären Code. 
\par
Sei $\Sigma = \{a_{1},a_{2},\ldots,a_{N},\}$ das $N$-elementige Quellalphabet mit zugehörigen Auftrittswahrscheinlichkeiten $p(a_1),\ldots , p(a_N)$ und $\mathfrak{t}:=a_{i_1}a_{i_2}\ldots a_{i_m}$ ein Text. Für $i=0,\ldots N$ definiert man die kumulierte Wahrscheinlichkeit
\begin{align*}
F(i):=\sum_{k=0}^{i}p(a_i),\quad F(0):=0.
\end{align*}
Eine {\it numerische Representation} von $\mathfrak{t}$ ist ein Bruch im Interval $\left.\left[l^{m} ,  u^{m},\right.\right)$ wobei
\begin{align*}
l^{1}:=F(i_1 -1)\quad u^1:=F(i_1)
\end{align*}
und
\begin{align*}
l^{k}&:=l^{k-1} + \left( u^{k-1} - l^{k-1}\right) \cdot F(i_{k} - 1)
\\
u^{k}&:=l^{k-1} + \left( u^{k-1} - l^{k-1}\right) \cdot F(i_{k}),\quad k=2,3,\ldots m.
\end{align*}
\begin{Beispiel}
Sei $\Sigma = \{a,b,c\}$ mit $p(a)=0.7$, $p(b) =0.2$ und $p(c)=0.1$ und $\mathfrak{t}=abb$.
Dann gilt $i_1=1$ und $i_2=i_3 =2$.
Dann erhält man
\begin{center}
\begin{tabular}{c|c|c}
$k$ & $l^k$ & $u^k$
\\
\hline
$1$ & $0.0$ & $0.7$
\\
\hline
$2$ & $0.49$ & $ 0.63$ 
\\
\hline
$3$ & $0.588$ & $0.616$
\end{tabular}
\end{center}
\end{Beispiel}
Als numerische Repräsentation lässt sich jetzt z.B das arithmetische Mittel
\begin{align*}
\mathfrak{T}^{}(a_{i_{1}}\ldots a_{i_{m}})= \frac{l^{m} + u^{m}}{2}
\end{align*}
wählen.
\vspace{0.5cm}
\\
\begin{minipage}[h]{.4\textwidth}
 Damit ist die einzige Information die zur Berechnung der numerischen Repräsentation benötig wird die Funktion $F$. Die Rekonstruktion der Folge aus $\mathfrak{T}$ erfolgt dann über nebenstehenden Algorithmus.
\vspace{0.5cm}
\\
\end{minipage}
\hfill
\begin{minipage}[h]{.5\textwidth}
\begin{tabular}{l}
Sei $l^{0}=0$, $u^{0}=1$
\\
{\tt{For k:=1 to m do}}
\\
{\tt{begin}}
\\
$\mathfrak{T}^{*}= (\mathfrak{T} - l^{k-1}) / (u^{k-1} - l^{k-1})$
\\
Finde $i_k$ so dass $F(i_k -1) \leq \mathfrak{T} < F(i_k)$
\\
{\tt{return}} $(a_{i_{k}})$;
\\
Berechne $l^{k}$ und $u^{k}$
\\
{\tt{end}}
\end{tabular}
\end{minipage}
\vspace{0.5cm}
\\
Sei $\mathfrak{T}(a_{i_{1}}a_{i_{2}}\ldots a_{i_{m}}) = (u^{m} - l^{m})/2$ eine numerische Repräsentation für die Folge $a_{i_{1}}a_{i_{2}}\ldots a_{i_{m}}$. Die binäre Darstellung der numerischen Repräsentation kann  beliebig lang bzw. unendlich sein. In diesem Kapitel zeigen wir, wie man die Repräsentation mit Hilfe einer kleinen Anzahl von Bits kodieren kann. 
\vspace{0.5cm}
\par
Es sei
$$
 p(a_{i_{1}}a_{i_{2}}\ldots a_{i_{m}}) = p(a_{i_{1}})·p(a_{i_{2}})...p(a_{i_{1}}),
$$
dann definiert man 
$$
l(a_{i_{1}}a_{i_{2}}\ldots a_{i_{m}}):=\left\lceil \text{log}\frac{1}{p(a_{i_{1}}a_{i_{2}}\ldots a_{i_{m}}) }\right\rceil + 1.
$$
Den binären Code der Repräsentation definiert man als $l(a_{i_{1}}a_{i_{2}}\ldots a_{i_{m}})$ höchstwertige Bits des Bruchs $\mathfrak{T}(a_{i_{1}}a_{i_{2}}\ldots a_{i_{m}})$. 
\begin{Beispiel}
Sei $\Sigma = \{a,b\}$, $p(a)=0.9$, $p(b)=0.1$ und die Länge $m=2$. Dann erhält man folgende Kodierung für alle Folgen:
\begin{center}
\begin{tabular}{c|c|c|c|c}
$x$ & $\mathfrak{T}(x)$ & binär & $l(x)$  & Code
\\
\hline
aa & 0.405 & 0.0110011110\ldots &  2 & 01
\\
\hline
ab & 0.855 & 0.1101101011\ldots & 5 & 11011
\\
\hline
ba & 0.945 & 0.1111000111\ldots & 5 & 11110
\\
\hline
bb & 0.995 &0.1111111010\ldots & 8 & 11111110
\end{tabular}
\end{center}
\end{Beispiel}
\newpage
\section{Entropiereduktion von Bilddateien}\label{Filter}
Die Komprimierung von Bilddateien kann durch eine Filterung erfolgen, welche mit Ausnahme des unten vorgestellten Filtertyps {\tt{none}} in einer Erniedrigung der Entropie resultieren kann. Im Folgenden sollen die implementierten Filter anhand eines Bildes ( i.F. als {\tt{img}} bezeichnet) mit den Dimensionen  h (Höhe), w (Breite) und c (Anzahl der Farbkanäle) kurz besprochen werden. Das Ergebnis der Vorfilterung wird mit {\tt{pre}}, das der Umkehrung mit {\tt{post}} bezeichnet. Zusätzlich müssen für die Umkehrung  Werte in einem container - der i.F. als {\tt{res}} bezeichnet wird - gespeichert werden. Die neben den Algorithmen gezeichneten Gitter dienen zur Verdeutlichung des gewählten Iterationsweges. 

\begin{Definition}
Sei  $(i,j) \in [0, h-1]\times[0, w-1]$ und $0\leq k < c$.
Dann bezeichnet  $\text{*}(i,j,k):=\text{*}_{i,j,k}$ den Wert von * an der Stelle $(i,j,k)$.
\end{Definition}
Die Wahl der Filter orientiert sich an \cite{png}, die Filtertypen 4 -- 9 wurden analog zu Filtertyp 2 entwickelt:
\subsection{Verwendete Filter}
\subsubsection{Filtertyp 0: {\tt{none}} }
Hierbei wird keine Vorfilterung betrieben. Jedes Byte von {\tt{img}} verbleibt unverändert.

\subsubsection{Filtertyp 1: {\tt{sub}}}
\begin{minipage}[h]{.6\textwidth}
Jedes Pixel von {\tt{img}} wird durch die Differenz zu seinem linken Nachbarn ersetzt. Für jeden Farbkanal wird die rechte Kante des Bildes gespeichert.
\vspace{1.5cm}
\end{minipage}
\hfill
\begin{minipage}[h]{.4\textwidth}
\begin{flushright}
\begin{tikzpicture}
 \draw
%    horizontal
		 (0.0,3.0) -- (4.0,3.0)
		(0.0,2.5) -- (4.0,2.5)
		(0.0,2.0) -- (4.0,2.0)
		(0.0,1.5) -- (4.0,1.5)
		(0.0,1.0) -- (4.0,1.0)
		(0.0,0.5) -- (4.0,0.5)
		(0.0,0.0) -- (4.0,0.0)
	%	vertical
		(0.0,3.0) -- (0.0,0.0)
		(0.5,3.0) -- (0.5,0.0)
		(1.0,3.0) -- (1.0,0.0)
		(1.5,3.0) -- (1.5,0.0)
		(2.0,3.0) -- (2.0,0.0)
		(2.5,3.0) -- (2.5,0.0)
		(3.0,3.0) -- (3.0,0.0)
		(3.5,3.0) -- (3.5,0.0)
		(4.0,3.0) -- (4.0,0.0)
		(3.75,2.75)node[]{$\downarrow$}
		(3.75,2.25)node[]{$\downarrow$}
		(3.75,1.75)node[]{$\downarrow$}
		(3.75,1.25)node[]{$\downarrow$}
		(3.75,0.75)node[]{$\downarrow$}
		(3.75,0.25)node[]{$\downarrow$}
		;	
\end{tikzpicture}
\end{flushright}
\end{minipage}
\par
\vspace{1cm}
\begin{tabular}{c|c}
Verschlüsselung & Entschlüsselung
\\
\hline
PROCEDURE ENCODE({\tt{img}},{\tt{pre}},{\tt{res}}) & PROCEDURE DECODE({\tt{pre}},{\tt{post}},{\tt{res}})
\\
new buffer; $x=1$; $y=0$; $k=0$; & {\tt{post}}.resize$((h-1)*(w-1)*c)$;
\\
{\tt{pre}}.resize$((h-1)*(w-1)*c)$; & $x=w-1$; $y=h-1$; $k=c-1$;
\\
{\tt{WHILE}}$(k < c)$ &                  {\tt{WHILE}}$(k > 0)$
\\
{\tt{WHILE}}$(y < h)$ &               $\text{buffer} = \text{{\tt{res}}}[k];$
\\
{\tt{WHILE}}$(x < w)$ &              {\tt{WHILE}}$(y>0)$
\\
$\text{{\tt{pre}}}_{x,y,k}\footnotemark\leftarrow \text{{\tt{img}}}_{x,y,k} - \text{{\tt{img}}}_{x-1,y,k};$ &  $\text{{\tt{post}}}_{x,y,k}\leftarrow \text{buffer}[y]$
\\
$x++$; & {\tt{WHILE}}$(x>1)$
\end{tabular}
\footnotetext{Die Berechnung muss ohne Überlauf erfolgen.}

\begin{center}
\begin{tabular}{c|c}
Verschlüsselung & Entschlüsselung
\\
\hline
{\tt{END {\tt{WHILE}}}} &  $\text{{\tt{post}}}_{x-1,y,k}\footnotemark[4]\leftarrow \text{{\tt{post}}}_{x,y,k} - \text{{\tt{pre}}}_{x,y,k};$
\\
buffer.save$(\text{{\tt{img}}}_{w-1,y,k})$;\;$x=1$; & $x--;$
\\
$y++$; &  {\tt{END {\tt{WHILE}}}}; 
\\
{\tt{END {\tt{WHILE}}}} & $y--;\;x=w-1;$ 
\\
{\tt{res}}$[k]$ = buffer;  & {\tt{END {\tt{WHILE}}}} 
\\
$k++;$ $y=1;$ &  $k--;$ 
\\
{\tt{END {\tt{WHILE}}}}  & {\tt{END {\tt{WHILE}}}} 
\\
END PROCEDURE & END PROCEDURE
\end{tabular}
\end{center}


\subsubsection{Filtertyp 2: {\tt{up}}}
\begin{minipage}[h]{.6\textwidth}
Jedes Pixel von {\tt{img}} wird durch die Differenz zu seinem oberen Nachbarn ersetzt. Für jeden Farbkanal wird die untere Kante des Bildes gespeichert.
\vspace{1.5cm}
\end{minipage}
\hfill
\begin{minipage}[h]{.4\textwidth}
\begin{flushright}
\begin{tikzpicture}
 \draw
%    horizontal
		 (0.0,3.0) -- (4.0,3.0)
		(0.0,2.5) -- (4.0,2.5)
		(0.0,2.0) -- (4.0,2.0)
		(0.0,1.5) -- (4.0,1.5)
		(0.0,1.0) -- (4.0,1.0)
		(0.0,0.5) -- (4.0,0.5)
		(0.0,0.0) -- (4.0,0.0)
	%	vertical
		(0.0,3.0) -- (0.0,0.0)
		(0.5,3.0) -- (0.5,0.0)
		(1.0,3.0) -- (1.0,0.0)
		(1.5,3.0) -- (1.5,0.0)
		(2.0,3.0) -- (2.0,0.0)
		(2.5,3.0) -- (2.5,0.0)
		(3.0,3.0) -- (3.0,0.0)
		(3.5,3.0) -- (3.5,0.0)
		(4.0,3.0) -- (4.0,0.0)
		(0.25,0.25)node[]{$\rightarrow$}
		(0.75,0.25)node[]{$\rightarrow$}
		(1.25,0.25)node[]{$\rightarrow$}
		(1.75,0.25)node[]{$\rightarrow$}
		(2.25,0.25)node[]{$\rightarrow$}
		(2.75,0.25)node[]{$\rightarrow$}
		(3.25,0.25)node[]{$\rightarrow$}
		(3.75,0.25)node[]{$\rightarrow$}
		;	
\end{tikzpicture}
\end{flushright}
\end{minipage}
\par
\vspace{1cm}

\begin{tabular}{c|c}
Verschlüsselung & Entschlüsselung
\\
\hline
PROCEDURE ENCODE({\tt{img}},{\tt{pre}},{\tt{res}}) & PROCEDURE DECODE({\tt{pre}},{\tt{post}},{\tt{res}})
\\
new buffer; $x=0$;$y=1$; $k=0$; & {\tt{post}}.resize$((h-1)*(w-1)*c)$;
\\
{\tt{pre}}.resize$((h-1)*(w-1)*c)$; & $x=w-1$;$y=h-1$; $k=c-1$;
\\
{\tt{WHILE}}$(k < c)$ &  {\tt{WHILE}}$(k > 0)$
\\
{\tt{WHILE}}$(x < w)$ &  $\text{buffer} = \text{{\tt{res}}}[k];$
\\
{\tt{WHILE}}$(y < h)$ &   {\tt{WHILE}}$(x>0)$
\\
$\text{{\tt{pre}}}_{x,y,k}\footnotemark[4]\leftarrow \text{{\tt{img}}}_{x,y,k} - \text{{\tt{img}}}_{x,y-1,k};$ &  $\text{{\tt{post}}}_{x,y,k}\leftarrow \text{buffer}[x];$
\\
$y++$; & {\tt{WHILE}}$(y>1)$
\\
{\tt{END {\tt{WHILE}}}} &  $\text{{\tt{post}}}_{x,y-1,k}\footnotemark[4]\leftarrow \text{{\tt{post}}}_{x,y,k} - \text{{\tt{pre}}}_{x,y,k};$
\\
buffer.save$(\text{{\tt{img}}}_{x,y,k})$;\;$y=1$; & $y--;$
\\
$x++$; & {\tt{END {\tt{WHILE}}}} 
\\
{\tt{END {\tt{WHILE}}}} &  $y=h-1;$ $x--;$
\\
{\tt{res}}$[k]$ = buffer;& {\tt{END {\tt{WHILE}}}} 
\\
 $k++;$ $x=1;$ &  $k--;$ 
\\
{\tt{END {\tt{WHILE}}}}  & {\tt{END {\tt{WHILE}}}}
\\ 
END PROCEDURE & END PROCEDURE
\end{tabular}

\subsubsection{Filtertyp 3: {\tt{average2}}}
\begin{minipage}[h]{.6\textwidth}
Jedes Pixel von {\tt{img}} wird durch die Differenz zu dem Mittelwert aus seinem linken und oberen  Nachbarn ersetzt. Für jeden Farbkanal wird die rechte Kante des Bildes gespeichert.
\vspace{1cm}
\end{minipage}
\hfill
\begin{minipage}[h]{.4\textwidth}
\begin{flushright}
\begin{tikzpicture}
 \draw
%    horizontal
		 (0.0,3.0) -- (4.0,3.0)
		(0.0,2.5) -- (4.0,2.5)
		(0.0,2.0) -- (4.0,2.0)
		(0.0,1.5) -- (4.0,1.5)
		(0.0,1.0) -- (4.0,1.0)
		(0.0,0.5) -- (4.0,0.5)
		(0.0,0.0) -- (4.0,0.0)
	%	vertical
		(0.0,3.0) -- (0.0,0.0)
		(0.5,3.0) -- (0.5,0.0)
		(1.0,3.0) -- (1.0,0.0)
		(1.5,3.0) -- (1.5,0.0)
		(2.0,3.0) -- (2.0,0.0)
		(2.5,3.0) -- (2.5,0.0)
		(3.0,3.0) -- (3.0,0.0)
		(3.5,3.0) -- (3.5,0.0)
		(4.0,3.0) -- (4.0,0.0)
		(3.75,2.75)node[]{$\downarrow$}
		(3.75,2.25)node[]{$\downarrow$}
		(3.75,1.75)node[]{$\downarrow$}
		(3.75,1.25)node[]{$\downarrow$}
		(3.75,0.75)node[]{$\downarrow$}
		(3.75,0.25)node[]{$\downarrow$}
		;	
\end{tikzpicture}
\end{flushright}
\end{minipage}
\par
\vspace{1cm}

\begin{tabular}{c|c}
Verschlüsselung & Entschlüsselung
\\
\hline
PROCEDURE ENCODE({\tt{img}},{\tt{pre}},{\tt{res}}) & PROCEDURE DECODE({\tt{pre}},{\tt{post}},{\tt{res}})
\\
new buffer; $x=0$; $y=0$; $k=0$; & {\tt{post}}.resize$((h-1)*(w-1)*c)$;
\\
{\tt{pre}}.resize$((h-1)*(w-1)*c)$; & $x=w-1$;$y=0$; $k=c-1$;
\\
{\tt{WHILE}}$(k < c)$ &                  {\tt{WHILE}}$(k > 0)$
\\
{\tt{WHILE}}$(y < h)$ &               $\text{buffer} = \text{{\tt{res}}}[k];$
\\
{\tt{WHILE}}$(x < w)$ &              {\tt{WHILE}}$(y<h)$
\\
$\text{{\tt{pre}}}_{x,y,k}\footnotemark[4]\leftarrow \text{{\tt{img}}}_{x,y,k} - 1/2 *(\text{{\tt{img}}}_{x-1,y,k}$ &  $\text{{\tt{post}}}_{x,y,k}\leftarrow \text{buffer}[y]$
\\
$+\;\text{{\tt{img}}}_{x,y-1,k});$  & {\tt{WHILE}}$(x>=1)$
\\
$x++;$ &  $\text{{\tt{post}}}_{x-1,y,k}\footnotemark[4]\leftarrow \text{{\tt{post}}}_{x,y,k} - 1/2* (\text{{\tt{post}}}_{x,y-1,k}$  
\\
{\tt{END {\tt{WHILE}}}}  & $+\;\text{{\tt{pre}}}_{x,y,k});$
\\
buffer.save$(\text{{\tt{img}}}_{x,y,k});$  & $x--;$
\\
$x=0$; $y++$;  &   {\tt{END {\tt{WHILE}}}}; 
\\
{\tt{END {\tt{WHILE}}}}   & $y++;$ 
\\
{\tt{res}}$[k]$ = buffer;  & $x=w-1;$ 
\\
$k++;$   &  {\tt{END {\tt{WHILE}}}}   
\\
$y=0;$ &   $k--;$
\\
{\tt{END {\tt{WHILE}}}} & {\tt{END {\tt{WHILE}}}} 
\\
END PROCEDURE & END PROCEDURE
\end{tabular}


\subsubsection{Filtertyp 4: {\tt{average3}}}
\begin{minipage}[h]{.6\textwidth}
Jedes Pixel von {\tt{img}} wird durch die Differenz zu dem Mittelwert aus seinem linken, oberen und rechten Nachbarn ersetzt. Für jeden Farbkanal wird die rechte Kante des Bildes gespeichert.
\vspace{1cm}
\end{minipage}
\hfill
\begin{minipage}[h]{.4\textwidth}
\begin{flushright}
\begin{tikzpicture}
 \draw
%    horizontal
		 (0.0,3.0) -- (4.0,3.0)
		(0.0,2.5) -- (4.0,2.5)
		(0.0,2.0) -- (4.0,2.0)
		(0.0,1.5) -- (4.0,1.5)
		(0.0,1.0) -- (4.0,1.0)
		(0.0,0.5) -- (4.0,0.5)
		(0.0,0.0) -- (4.0,0.0)
	%	vertical
		(0.0,3.0) -- (0.0,0.0)
		(0.5,3.0) -- (0.5,0.0)
		(1.0,3.0) -- (1.0,0.0)
		(1.5,3.0) -- (1.5,0.0)
		(2.0,3.0) -- (2.0,0.0)
		(2.5,3.0) -- (2.5,0.0)
		(3.0,3.0) -- (3.0,0.0)
		(3.5,3.0) -- (3.5,0.0)
		(4.0,3.0) -- (4.0,0.0)
		(3.75,2.75)node[]{$\downarrow$}
		(3.75,2.25)node[]{$\downarrow$}
		(3.75,1.75)node[]{$\downarrow$}
		(3.75,1.25)node[]{$\downarrow$}
		(3.75,0.75)node[]{$\downarrow$}
		(3.75,0.25)node[]{$\downarrow$}
		;	
\end{tikzpicture}
\end{flushright}
\end{minipage}

\begin{tabular}{c|c}
Verschlüsselung & Entschlüsselung
\\
\hline
PROCEDURE ENCODE({\tt{img}},{\tt{pre}},{\tt{res}}) & PROCEDURE DECODE({\tt{pre}},{\tt{post}},{\tt{res}})
\\
new buffer; $x=0$; $y=0$; $k=0$ & {\tt{post}}.resize$((h-1)*(w-1)*c)$;
\\
{\tt{pre}}.resize$((h-1)*(w-1)*c)$; & $x=w-1$;$y=0$; $k=c-1$
\\
{\tt{WHILE}}$(k < c)$ &                  {\tt{WHILE}}$(k > 0)$
\\
{\tt{WHILE}}$(y < h)$ &               $\text{buffer} = \text{{\tt{res}}}[k];$
\\
{\tt{WHILE}}$(x < w)$ &              {\tt{WHILE}}$(y<h)$
\\
$\text{{\tt{pre}}}_{x,y,k}\footnotemark[4]\leftarrow \text{{\tt{img}}}_{x,y,k} - 1/3 *(\text{{\tt{img}}}_{x-1,y,k}$ &  $\text{{\tt{post}}}_{x,y,k}\leftarrow \text{buffer}[y];$
\\
$+\;\text{{\tt{img}}}_{x,y-1,k} + \text{{\tt{img}}}_{x+1,y,k});$  & {\tt{WHILE}}$(x>1)$
\\
$x++;$ &  $\text{{\tt{post}}}_{x-1,y,k}\footnotemark[4]\leftarrow \text{{\tt{post}}}_{x,y,k} - 1/3 *(\text{{\tt{post}}}_{x,y-1,k} $    
\\
{\tt{END {\tt{WHILE}}}}  & $+\;\text{{\tt{post}}}_{x+1,y,k} + \text{{\tt{pre}}}_{x,y,k});$
\\
buffer.save$(\text{{\tt{img}}}_{x,y,k});$  & $x--;$
\\
$x=0$; $y++$;  &   {\tt{END {\tt{WHILE}}}}; 
\\
{\tt{END {\tt{WHILE}}}}   & $y++;\;x=w-1;$ 
\\
{\tt{res}}$[k]$ = buffer;  &  {\tt{END {\tt{WHILE}}}} 
\\
$k++;$ $y=0;$   &   $k--;$ 
\\
{\tt{END {\tt{WHILE}}}} & {\tt{END {\tt{WHILE}}}} 
\\
END PROCEDURE & END PROCEDURE
\end{tabular}

\subsubsection{Filtertyp 5: {\tt{average4}}}
\begin{minipage}[h]{.6\textwidth}
Jedes Pixel von {\tt{img}} wird durch die Differenz zu dem Mittelwert aus seinem linken, oberen, rechten und unteren Nachbarn ersetzt. Für jeden Farbkanal wird die untere Kante des Bildes gespeichert.
\vspace{1cm}
\end{minipage}
\hfill
\begin{minipage}[h]{.4\textwidth}
\begin{flushright}
\begin{tikzpicture}
 \draw
%    horizontal
		 (0.0,3.0) -- (4.0,3.0)
		(0.0,2.5) -- (4.0,2.5)
		(0.0,2.0) -- (4.0,2.0)
		(0.0,1.5) -- (4.0,1.5)
		(0.0,1.0) -- (4.0,1.0)
		(0.0,0.5) -- (4.0,0.5)
		(0.0,0.0) -- (4.0,0.0)
	%	vertical
		(0.0,3.0) -- (0.0,0.0)
		(0.5,3.0) -- (0.5,0.0)
		(1.0,3.0) -- (1.0,0.0)
		(1.5,3.0) -- (1.5,0.0)
		(2.0,3.0) -- (2.0,0.0)
		(2.5,3.0) -- (2.5,0.0)
		(3.0,3.0) -- (3.0,0.0)
		(3.5,3.0) -- (3.5,0.0)
		(4.0,3.0) -- (4.0,0.0)
		(0.25,0.25)node[]{$\rightarrow$}
		(0.75,0.25)node[]{$\rightarrow$}
		(1.25,0.25)node[]{$\rightarrow$}
		(1.75,0.25)node[]{$\rightarrow$}
		(2.25,0.25)node[]{$\rightarrow$}
		(2.75,0.25)node[]{$\rightarrow$}
		(3.25,0.25)node[]{$\rightarrow$}
		(3.75,0.25)node[]{$\rightarrow$}
		;	
\end{tikzpicture}
\end{flushright}
\end{minipage}
\par
\vspace{1cm}
\begin{tabular}{c|c}
Verschlüsselung & Entschlüsselung
\\
\hline
PROCEDURE ENCODE({\tt{img}},{\tt{pre}},{\tt{res}}) & PROCEDURE DECODE({\tt{pre}},{\tt{post}},{\tt{res}})
\\
new buffer; $x=0$; $y=0$; $k=0$; & {\tt{post}}.resize$((h-1)*(w-1)*c)$;
\\
{\tt{pre}}.resize$((h-1)*(w-1)*c)$; & $x=0$; $y=h-1$; $k=c-1$;
\\
{\tt{WHILE}}$(k < c)$ &                  {\tt{WHILE}}$(k > 0)$
\\
{\tt{WHILE}}$(x < w)$ &               $\text{buffer} = \text{{\tt{res}}}[k];$
\\
{\tt{WHILE}}$(y < h)$ &            write(buffer);
\\
$\text{{\tt{pre}}}_{x,y,k}\footnotemark[4]\leftarrow \text{{\tt{img}}}_{x,y,k} - 1/4 *(\text{{\tt{img}}}_{x-1,y,k}$ & {\tt{WHILE}}$(y > 0)$ 
\\
$+\;\text{{\tt{img}}}_{x,y-1,k} + \text{{\tt{img}}}_{x+1,y,k}$  &  {\tt{WHILE}}$(x<w)$
\\
$+\;\text{{\tt{img}}}_{x,y+1,k});$ & $\text{{\tt{post}}}_{x,y-1,k}\footnotemark[4]\leftarrow \text{{\tt{post}}}_{x,y,k} - 1/4 *(\text{{\tt{post}}}_{x-1,y,k} $ 
\\
$y++;$ &   $+\;\text{{\tt{post}}}_{x+1,y,k}  + \text{{\tt{post}}}_{x,y+1,k}$  
\\
{\tt{END {\tt{WHILE}}}}  & $+\;\text{{\tt{pre}}}_{x,y,k});$
\\
buffer.save$(\text{{\tt{img}}}_{x,y,k});$  & $x++;$
\\
$y=0$; $x++$;  &   {\tt{END {\tt{WHILE}}}}; 
\end{tabular}
\begin{center}
\begin{tabular}{c|c}
Verschlüsselung & Entschlüsselung
\\
\hline
{\tt{END {\tt{WHILE}}}}   & $y--;\;x=0;$ 
\\
{\tt{res}}$[k]$ = buffer;  &  {\tt{END {\tt{WHILE}}}} 
\\
$k++;$ $x=0;$   &   $k--;$ $y=h-1$;
\\
{\tt{END {\tt{WHILE}}}} & {\tt{END {\tt{WHILE}}}} 
\\
END PROCEDURE & END PROCEDURE
\end{tabular}
\end{center}

\subsubsection{Filtertyp 6: {\tt{average5}}}
\begin{minipage}[h]{.6\textwidth}
Jedes Pixel von {\tt{img}} wird durch die Differenz zu dem Mittelwert aus seinem linken, links oberen, oberen, rechten und unteren Nachbarn ersetzt. Für jeden Farbkanal wird die untere Kante des Bildes gespeichert.
\vspace{0.5cm}
\end{minipage}
\hfill
\begin{minipage}[h]{.4\textwidth}
\begin{flushright}
\begin{tikzpicture}
 \draw
%    horizontal
		 (0.0,3.0) -- (4.0,3.0)
		(0.0,2.5) -- (4.0,2.5)
		(0.0,2.0) -- (4.0,2.0)
		(0.0,1.5) -- (4.0,1.5)
		(0.0,1.0) -- (4.0,1.0)
		(0.0,0.5) -- (4.0,0.5)
		(0.0,0.0) -- (4.0,0.0)
	%	vertical
		(0.0,3.0) -- (0.0,0.0)
		(0.5,3.0) -- (0.5,0.0)
		(1.0,3.0) -- (1.0,0.0)
		(1.5,3.0) -- (1.5,0.0)
		(2.0,3.0) -- (2.0,0.0)
		(2.5,3.0) -- (2.5,0.0)
		(3.0,3.0) -- (3.0,0.0)
		(3.5,3.0) -- (3.5,0.0)
		(4.0,3.0) -- (4.0,0.0)
		(0.25,0.25)node[]{$\rightarrow$}
		(0.75,0.25)node[]{$\rightarrow$}
		(1.25,0.25)node[]{$\rightarrow$}
		(1.75,0.25)node[]{$\rightarrow$}
		(2.25,0.25)node[]{$\rightarrow$}
		(2.75,0.25)node[]{$\rightarrow$}
		(3.25,0.25)node[]{$\rightarrow$}
		(3.75,0.25)node[]{$\rightarrow$}
		;	
\end{tikzpicture}
\end{flushright}
\end{minipage}
\par
\vspace{1cm}

\begin{tabular}{c|c}
Verschlüsselung & Entschlüsselung
\\
\hline
PROCEDURE ENCODE({\tt{img}},{\tt{pre}},{\tt{res}}) & PROCEDURE DECODE({\tt{pre}},{\tt{post}},{\tt{res}})
\\
new buffer; $x=0$; $y=0$; $k=0$; & {\tt{post}}.resize$((h-1)*(w-1)*c)$;
\\
{\tt{pre}}.resize$((h-1)*(w-1)*c)$; & $x=0$; $y=h-1$; $k=c-1$;
\\
{\tt{WHILE}}$(k < c)$ &                  {\tt{WHILE}}$(k > 0)$
\\
{\tt{WHILE}}$(x < w)$ &               $\text{buffer} = \text{{\tt{res}}}[k];$
\\
{\tt{WHILE}}$(y < h)$ &            write(buffer);
\\
$\text{{\tt{pre}}}_{x,y,k}\footnotemark[4]\leftarrow \text{{\tt{img}}}_{x,y,k} - 1/5 *(\text{{\tt{img}}}_{x-1,y,k}$ & {\tt{WHILE}}$(y > 0)$ 
\\
$+\;\text{{\tt{img}}}_{x-1,y-1,k} + \text{{\tt{img}}}_{x,y-1,k}$  &  {\tt{WHILE}}$(x<w)$
\\
$+\;\text{{\tt{img}}}_{x+1,y,k} + \text{{\tt{img}}}_{x,y+1,k});$ & $\text{{\tt{post}}}_{x,y-1,k}\footnotemark[4]\leftarrow \text{{\tt{post}}}_{x,y,k} - 1/5 *(\text{{\tt{post}}}_{x-1,y,k} $ 
\\
$y++;$ &   $+\;\text{{\tt{post}}}_{x-1,y-1,k} + \text{{\tt{post}}}_{x+1,y,k}$  
\\
{\tt{END {\tt{WHILE}}}}  & $+\;\text{{\tt{post}}}_{x,y+1,k} + \text{{\tt{pre}}}_{x,y,k});$
\\
buffer.save$(\text{{\tt{img}}}_{x,y,k});$  & $x++;$
\\
$y=0$; $x++$;  &   {\tt{END {\tt{WHILE}}}}; 
\\
{\tt{END {\tt{WHILE}}}}   & $y--;\;x=0;$ 
\\
{\tt{res}}$[k]$ = buffer;  &  {\tt{END {\tt{WHILE}}}} 
\\
$k++;$ $x=0;$   &   $k--;$ $y=h-1$;
\\
{\tt{END {\tt{WHILE}}}} & {\tt{END {\tt{WHILE}}}} 
\\
END PROCEDURE & END PROCEDURE
\end{tabular}

\subsubsection{Filtertyp 7: {\tt{average6}}}
\begin{minipage}[h]{.6\textwidth}
Jedes Pixel von {\tt{img}} wird durch die Differenz zu dem Mittelwert aus seinem linken, links oberen, oberen, rechts oberen, rechten und unteren Nachbarn ersetzt. Für jeden Farbkanal wird die linke und die untere Kante des Bildes gespeichert.
\vspace{0.5cm}
\end{minipage}
\hfill
\begin{minipage}[h]{.4\textwidth}
\begin{flushright}
\begin{tikzpicture}
 \draw
%    horizontal
		 (0.0,3.0) -- (4.0,3.0)
		(0.0,2.5) -- (4.0,2.5)
		(0.0,2.0) -- (4.0,2.0)
		(0.0,1.5) -- (4.0,1.5)
		(0.0,1.0) -- (4.0,1.0)
		(0.0,0.5) -- (4.0,0.5)
		(0.0,0.0) -- (4.0,0.0)
	%	vertical
		(0.0,3.0) -- (0.0,0.0)
		(0.5,3.0) -- (0.5,0.0)
		(1.0,3.0) -- (1.0,0.0)
		(1.5,3.0) -- (1.5,0.0)
		(2.0,3.0) -- (2.0,0.0)
		(2.5,3.0) -- (2.5,0.0)
		(3.0,3.0) -- (3.0,0.0)
		(3.5,3.0) -- (3.5,0.0)
		(4.0,3.0) -- (4.0,0.0)
		
		(0.25,2.75)node[]{$\downarrow$}
		(0.25,2.25)node[]{$\downarrow$}
		(0.25,1.75)node[]{$\downarrow$}
		(0.25,1.25)node[]{$\downarrow$}
		(0.25,0.75)node[]{$\downarrow$}
				
		(0.25,0.25)node[]{$\rightarrow$}
		(0.75,0.25)node[]{$\rightarrow$}
		(1.25,0.25)node[]{$\rightarrow$}
		(1.75,0.25)node[]{$\rightarrow$}
		(2.25,0.25)node[]{$\rightarrow$}
		(2.75,0.25)node[]{$\rightarrow$}
		(3.25,0.25)node[]{$\rightarrow$}
		(3.75,0.25)node[]{$\rightarrow$}
		;	
\end{tikzpicture}
\end{flushright}
\end{minipage}
\par
\vspace{1cm}

\begin{tabular}{c|c}
Verschlüsselung & Entschlüsselung
\\
\hline
PROCEDURE ENCODE({\tt{img}},{\tt{pre}},{\tt{res}}) & PROCEDURE DECODE({\tt{pre}},{\tt{post}},{\tt{res}})
\\
new buffer; $x=0$; $y=0$; $k=0$; & {\tt{post}}.resize$((h-1)*(w-1)*c)$;
\\
{\tt{pre}}.resize$((h-1)*(w-1)*c)$; & $x=0$; $y=h-1$; $k=c-1$;
\\
{\tt{WHILE}}$(k < c)$ &                  {\tt{WHILE}}$(k > 0)$
\\
{\tt{res}}$[k]$ = Process(buffer); &  $\text{buffer} = \text{{\tt{res}}}[k];$
\\
buffer.clear(); & write(buffer); 
\\
{\tt{WHILE}}$(x < w)$ &   {\tt{WHILE}}$(y > 0)$          
\\
{\tt{WHILE}}$(y < h)$ &   {\tt{WHILE}}$(x<w)$     
\\
$\text{{\tt{pre}}}_{x,y,k}\footnotemark[4]\leftarrow \text{{\tt{img}}}_{x,y,k} - 1/6 *(\text{{\tt{img}}}_{x-1,y,k}$ &  $\text{{\tt{post}}}_{x+1,y-1,k}\footnotemark[4]\leftarrow \text{{\tt{post}}}_{x,y,k} - 1/6 *(\text{{\tt{post}}}_{x-1,y,k} $ 
\\
$+\;\text{{\tt{img}}}_{x-1,y-1,k} + \text{{\tt{img}}}_{x,y-1,k}$ & $+\;\text{{\tt{post}}}_{x-1,y-1,k} + \text{{\tt{post}}}_{x,y-1,k}$  
\\
$+\;\text{{\tt{img}}}_{x+1,y-1,k} + \text{{\tt{img}}}_{x+1,y,k};$ & $+\;\text{{\tt{post}}}_{x+1,y,k} + \text{{\tt{post}}}_{x,y+1,k}  $
\\
 $+\;\text{{\tt{img}}}_{x,y+1,k});$    &   $+\; \text{{\tt{pre}}}_{x,y,k});$
\\
 $y++;$  & $x++;$
\\
{\tt{END {\tt{WHILE}}}}   & {\tt{END {\tt{WHILE}}}};
\\
$x++$; $y=0$;    & $y--;\;x=0;$  
\\
{\tt{END {\tt{WHILE}}}}   & {\tt{END {\tt{WHILE}}}} 
\\
$k++;$ $x=0;$  &  $k--;$ $y=h-1$;
\\
{\tt{END {\tt{WHILE}}}}    &   {\tt{END {\tt{WHILE}}}} 
\\
END PROCEDURE & END PROCEDURE
\end{tabular}

\subsubsection{Filtertyp 8: {\tt{average7}}}
\begin{minipage}[h]{.6\textwidth}
Jedes Pixel von {\tt{img}} wird durch die Differenz zu dem Mittelwert aus seinem linken, links oberen, oberen, rechts oberen, rechten, rechts unteren und unteren Nachbarn ersetzt. Für jeden Farbkanal wird die linke und die untere Kante des Bildes gespeichert.
\vspace{0.5cm}
\end{minipage}
\hfill
\begin{minipage}[h]{.4\textwidth}
\begin{flushright}
\begin{tikzpicture}
 \draw
%    horizontal
		 (0.0,3.0) -- (4.0,3.0)
		(0.0,2.5) -- (4.0,2.5)
		(0.0,2.0) -- (4.0,2.0)
		(0.0,1.5) -- (4.0,1.5)
		(0.0,1.0) -- (4.0,1.0)
		(0.0,0.5) -- (4.0,0.5)
		(0.0,0.0) -- (4.0,0.0)
	%	vertical
		(0.0,3.0) -- (0.0,0.0)
		(0.5,3.0) -- (0.5,0.0)
		(1.0,3.0) -- (1.0,0.0)
		(1.5,3.0) -- (1.5,0.0)
		(2.0,3.0) -- (2.0,0.0)
		(2.5,3.0) -- (2.5,0.0)
		(3.0,3.0) -- (3.0,0.0)
		(3.5,3.0) -- (3.5,0.0)
		(4.0,3.0) -- (4.0,0.0)
		
		(0.25,2.75)node[]{$\downarrow$}
		(0.25,2.25)node[]{$\downarrow$}
		(0.25,1.75)node[]{$\downarrow$}
		(0.25,1.25)node[]{$\downarrow$}
		(0.25,0.75)node[]{$\downarrow$}
				
		(0.25,0.25)node[]{$\rightarrow$}
		(0.75,0.25)node[]{$\rightarrow$}
		(1.25,0.25)node[]{$\rightarrow$}
		(1.75,0.25)node[]{$\rightarrow$}
		(2.25,0.25)node[]{$\rightarrow$}
		(2.75,0.25)node[]{$\rightarrow$}
		(3.25,0.25)node[]{$\rightarrow$}
		(3.75,0.25)node[]{$\rightarrow$}
		;	
\end{tikzpicture}
\end{flushright}
\end{minipage}
\par
\vspace{1cm}

\begin{tabular}{c|c}
Verschlüsselung & Entschlüsselung
\\
\hline
PROCEDURE ENCODE({\tt{img}},{\tt{pre}},{\tt{res}}) & PROCEDURE DECODE({\tt{pre}},{\tt{post}},{\tt{res}})
\\
new buffer; $x=0$; $y=0$; $k=0$; & {\tt{post}}.resize$((h-1)*(w-1)*c)$;
\\
{\tt{pre}}.resize$((h-1)*(w-1)*c)$; & $x=0$; $y=h-1$; $k=c-1$;
\\
{\tt{WHILE}}$(k < c)$ &                  {\tt{WHILE}}$(k > 0)$
\\
{\tt{res}}$[k]$ = Process(buffer);  &  $\text{buffer} = \text{{\tt{res}}}[k];$
\\
buffer.clear(); & write(buffer);
\\
{\tt{WHILE}}$(x < w)$ &   {\tt{WHILE}}$(y > 0)$          
\\
{\tt{WHILE}}$(y < h)$ &   {\tt{WHILE}}$(x<w)$     
\\
$\text{{\tt{pre}}}_{x,y,k}\footnotemark[4]\leftarrow \text{{\tt{img}}}_{x,y,k} - 1/7 *(\text{{\tt{img}}}_{x-1,y,k}$ &  $\text{{\tt{post}}}_{x+1,y-1,k}\footnotemark[4]\leftarrow \text{{\tt{post}}}_{x,y,k} - 1/7 *(\text{{\tt{post}}}_{x-1,y,k} $ 
\\
$+\;\text{{\tt{img}}}_{x-1,y-1,k} + \text{{\tt{img}}}_{x,y-1,k}$ & $+\;\text{{\tt{post}}}_{x-1,y-1,k} + \text{{\tt{post}}}_{x,y-1,k}$  
\\
$+\;\text{{\tt{img}}}_{x+1,y-1,k} + \text{{\tt{img}}}_{x+1,y,k}$ & $+\;\text{{\tt{post}}}_{x+1,y,k} + \text{{\tt{post}}}_{x+1,y+1,k}  $
\\
 $+\;\text{{\tt{img}}}_{x+1,y+1,k} +\;\text{{\tt{img}}}_{x,y+1,k});$    &   $+\;\text{{\tt{post}}}_{x,y+1,k} + \text{{\tt{pre}}}_{x,y,k});$
\\
 $y++;$  & $x++;$
\\
{\tt{END {\tt{WHILE}}}}   & {\tt{END {\tt{WHILE}}}};
\\
$x++$; $y=0$;    & $y--;\;x=0;$  
\\
{\tt{END {\tt{WHILE}}}}   & {\tt{END {\tt{WHILE}}}} 
\\
$k++;$ $x=0;$  &  $k--;$ $y=h-1$;
\\
{\tt{END {\tt{WHILE}}}}    &   {\tt{END {\tt{WHILE}}}} 
\\
END PROCEDURE & END PROCEDURE
\end{tabular}

\subsubsection{Filtertyp 9: {\tt{average8}}}
\begin{minipage}[h]{.6\textwidth}
Jedes Pixel von {\tt{img}} wird durch die Differenz zu dem Mittelwert aus seinem linken, links oberen, oberen, rechts oberen, rechten, rechts unteren, unteren und links unteren Nachbarn ersetzt. Für jeden Farbkanal wird die linke und die untere Kante des Bildes gespeichert.
\vspace{0.5cm}
\end{minipage}
\hfill
\begin{minipage}[h]{.4\textwidth}
\begin{flushright}
\begin{tikzpicture}
 \draw
%    horizontal
		 (0.0,3.0) -- (4.0,3.0)
		(0.0,2.5) -- (4.0,2.5)
		(0.0,2.0) -- (4.0,2.0)
		(0.0,1.5) -- (4.0,1.5)
		(0.0,1.0) -- (4.0,1.0)
		(0.0,0.5) -- (4.0,0.5)
		(0.0,0.0) -- (4.0,0.0)
	%	vertical
		(0.0,3.0) -- (0.0,0.0)
		(0.5,3.0) -- (0.5,0.0)
		(1.0,3.0) -- (1.0,0.0)
		(1.5,3.0) -- (1.5,0.0)
		(2.0,3.0) -- (2.0,0.0)
		(2.5,3.0) -- (2.5,0.0)
		(3.0,3.0) -- (3.0,0.0)
		(3.5,3.0) -- (3.5,0.0)
		(4.0,3.0) -- (4.0,0.0)
		
		(0.25,2.75)node[]{$\downarrow$}
		(0.25,2.25)node[]{$\downarrow$}
		(0.25,1.75)node[]{$\downarrow$}
		(0.25,1.25)node[]{$\downarrow$}
		(0.25,0.75)node[]{$\downarrow$}
				
		(0.25,0.25)node[]{$\rightarrow$}
		(0.75,0.25)node[]{$\rightarrow$}
		(1.25,0.25)node[]{$\rightarrow$}
		(1.75,0.25)node[]{$\rightarrow$}
		(2.25,0.25)node[]{$\rightarrow$}
		(2.75,0.25)node[]{$\rightarrow$}
		(3.25,0.25)node[]{$\rightarrow$}
		(3.75,0.25)node[]{$\rightarrow$}
		;	
\end{tikzpicture}
\end{flushright}
\end{minipage}
\par
\vspace{1cm}

\begin{tabular}{c|c}
Verschlüsselung & Entschlüsselung
\\
\hline
PROCEDURE ENCODE({\tt{img}},{\tt{pre}},{\tt{res}}) & PROCEDURE DECODE({\tt{pre}},{\tt{post}},{\tt{res}})
\\
new buffer; $x=0$; $y=0$; $k=0$; & {\tt{post}}.resize$((h-1)*(w-1)*c)$;
\\
{\tt{pre}}.resize$((h-1)*(w-1)*c)$; & $x=0$; $y=h-1$; $k=c-1$;
\\
{\tt{WHILE}}$(k < c)$ &                  {\tt{WHILE}}$(k > 0)$
\\
{\tt{res}}$[k]$ = Process(buffer); &  $\text{buffer} = \text{{\tt{res}}}[k];$
\\
buffer.clear(); & write(buffer);
\\
{\tt{WHILE}}$(x < w)$ &   {\tt{WHILE}}$(y > 0)$          
\\
{\tt{WHILE}}$(y < h)$ &   {\tt{WHILE}}$(x<w)$     
\\
$\text{{\tt{pre}}}_{x,y,k}\footnotemark[4]\leftarrow \text{{\tt{img}}}_{x,y,k} - 1/8 *(\text{{\tt{img}}}_{x-1,y,k}$ &  $\text{{\tt{post}}}_{x+1,y-1,k}\footnotemark[4]\leftarrow \text{{\tt{post}}}_{x,y,k} - 1/8 *(\text{{\tt{post}}}_{x-1,y,k} $ 
\\
$+\;\text{{\tt{img}}}_{x-1,y-1,k} + \text{{\tt{img}}}_{x,y-1,k}$ & $+\;\text{{\tt{post}}}_{x-1,y-1,k} + \text{{\tt{post}}}_{x,y-1,k}$  
\\
$+\;\text{{\tt{img}}}_{x+1,y-1,k} + \text{{\tt{img}}}_{x+1,y,k}$ & $+\;\text{{\tt{post}}}_{x+1,y,k} + \text{{\tt{post}}}_{x+1,y+1,k}  $
\end{tabular}
\par

\begin{center}
\begin{tabular}{c|c}
Verschlüsselung & Entschlüsselung
\\
\hline
 $+\;\text{{\tt{img}}}_{x+1,y+1,k} +\;\text{{\tt{img}}}_{x,y+1,k}$    &   $+\;\text{{\tt{post}}}_{x,y+1,k} + \text{{\tt{post}}}_{x-1,y+1,k} $
\\
$+\;\text{{\tt{img}}}_{x-1,y+1,k});$ & $+\;\text{{\tt{pre}}}_{x,y,k});$   
\\
$y++;$ & $x++;$
\\
{\tt{END {\tt{WHILE}}}}   & {\tt{END {\tt{WHILE}}}};
\\
$x++$; $y=0$;    & $y--;\;x=0;$  
\\
{\tt{END {\tt{WHILE}}}}   & {\tt{END {\tt{WHILE}}}} 
\\
$k++;$ $x=0;$  &  $k--;$ $y=h-1$;
\\
{\tt{END {\tt{WHILE}}}}    &   {\tt{END {\tt{WHILE}}}} 
\\
END PROCEDURE & END PROCEDURE
\end{tabular}
\end{center}

\subsubsection{Filtertyp 10: {\tt{paeth}}}
\begin{minipage}[h]{.6\textwidth}
Jedes Pixel von {\tt{img}} wird seinen {\tt{paeth}}-Prädiktor ersetzt. Für jeden Farbkanal wird die linke Kante des Bildes gespeichert.
\vspace{0.5cm}
\end{minipage}
\hfill
\begin{minipage}[h]{.4\textwidth}
\begin{flushright}
\begin{tikzpicture}
 \draw
%    horizontal
		 (0.0,3.0) -- (4.0,3.0)
		(0.0,2.5) -- (4.0,2.5)
		(0.0,2.0) -- (4.0,2.0)
		(0.0,1.5) -- (4.0,1.5)
		(0.0,1.0) -- (4.0,1.0)
		(0.0,0.5) -- (4.0,0.5)
		(0.0,0.0) -- (4.0,0.0)
	%	vertical
		(0.0,3.0) -- (0.0,0.0)
		(0.5,3.0) -- (0.5,0.0)
		(1.0,3.0) -- (1.0,0.0)
		(1.5,3.0) -- (1.5,0.0)
		(2.0,3.0) -- (2.0,0.0)
		(2.5,3.0) -- (2.5,0.0)
		(3.0,3.0) -- (3.0,0.0)
		(3.5,3.0) -- (3.5,0.0)
		(4.0,3.0) -- (4.0,0.0)
		
		(0.25,2.75)node[]{$\downarrow$}
		(0.25,2.25)node[]{$\downarrow$}
		(0.25,1.75)node[]{$\downarrow$}
		(0.25,1.25)node[]{$\downarrow$}
		(0.25,0.75)node[]{$\downarrow$}
		(0.25,0.25)node[]{$\downarrow$};	
\end{tikzpicture}
\end{flushright}
\end{minipage}
\par
\vspace{1cm}

\begin{tabular}{c|c}
Verschlüsselung & Entschlüsselung
\\
\hline
PROCEDURE ENCODE({\tt{img}},{\tt{pre}},{\tt{res}}) & PROCEDURE DECODE({\tt{pre}},{\tt{post}},{\tt{res}})
\\
new buffer; $x=0$; $y=0$; $k=0$; & {\tt{post}}.resize$((h-1)*(w-1)*c)$;
\\
{\tt{pre}}.resize$((h-1)*(w-1)*c)$; & $x=1$; $y=0$; $k=c-1$;
\\
{\tt{WHILE}}$(k < c)$ &                  {\tt{WHILE}}$(k > 0)$
\\
{\tt{WHILE}}$(y < h)$ &               $\text{buffer} = \text{{\tt{res}}}[k];$
\\
buffer.save$(\text{{\tt{img}}}_{0,y,k})$; &  {\tt{WHILE}}$(y < h)$
\\
{\tt{WHILE}}$(x < w)$ &  $\text{{\tt{post}}}_{x-1,y,k}\leftarrow \text{buffer}[y]$        
\\
$\text{{\tt{pre}}}_{x,y,k}\footnotemark[4]\leftarrow \text{{\tt{paeth}}}(\text{{\tt{img}}}_{x,y,k})$ & {\tt{WHILE}}$(x>1)$
\\
$x++$; &  $\text{{\tt{post}}}_{x,y,k}\footnotemark[4]\leftarrow \text{{\tt{paeth}}}(\text{{\tt{post}}}_{x,y,k}) + \text{{\tt{pre}}}_{x,y,k};$
\\
{\tt{END {\tt{WHILE}}}} & $x++;$
\\
$x=0$; $y++$; & {\tt{END {\tt{WHILE}}}}
\\
 {\tt{END {\tt{WHILE}}}} &  $y++;\;x=1;$
\\
 {\tt{res}}$[k]$ = buffer; &  {\tt{END {\tt{WHILE}}}} 
\\
$k++;$ $y=0;$  & $k--;$
\\
{\tt{END {\tt{WHILE}}}} & {\tt{END {\tt{WHILE}}}}  
\\
END PROCEDURE  &  END PROCEDURE
\end{tabular}

Hierbei ermittelt der {\tt{paeth}}-prediktor folgenden Wert
\begin{align*}
\text{{\tt{paeth}}}(\text{{\tt{img}}}_{x,y,k})&:= \text{{\tt{img}}}_{x-1,y,k}  + \text{{\tt{img}}}_{x,y-1,k} - \text{{\tt{img}}}_{x-1,y-1,k};
\\
\text{left}&:=\left|\text{{\tt{img}}}_{x-1,y,k} - \text{PAETH}(\text{{\tt{img}}}_{x,y,k})\right|; 
\\
\text{up}&:=\left|\text{{\tt{img}}}_{x,y-1,k} - \text{PAETH}(\text{{\tt{img}}}_{x,y,k})\right|;
\\
\text{leftUp}&:=\left|\text{{\tt{img}}}_{x-1,y-1,k} - \text{PAETH}(\text{{\tt{img}}}_{x,y,k})\right|;
\\
\text{{\tt{IF}}}(\text{left}& \leq \text{up} \;\&\&\;  \text{left} \leq \text{leftUp})
\\
\text{{\tt{return}} left;}
\\
\text{{\tt{{\tt{ELSE}} {\tt{IF}}}}}(\text{up}& \leq \text{leftUp})
\\
\text{{\tt{return}} up;}
\\
\text{{\tt{return}} leftUp;}
\end{align*}

\subsection{Fazit zur Wahl der Filter}
Sämtliche Filtertypen lassen sich für jeden Farbkanal parallel verarbeiten, zusätzlich lässt sich der Filtertyp {\tt{sub}} für jede Reihe und der Filtertyp {\tt{up}} für jede Spalte parallelisieren. Eine Tabelle die den Einfluss der Filterung auf die Entropie wiedergibt, findet sich in den Ergebnissen.
\newpage
\section{Asymmetrische Zahlensysteme}\label{ANS}
\subsection{Einführung}
Sei $\A:=\{a_{1},a_{2},...,a_{n-1}\}$  ein endliches Alphabets, $\{p_{s}\}_{s\in \A}\, $ die Folge der zugehörigen Auftrittswahrscheinlichkeiten mit
$\sum_{s\in \A} p_{s} =1$ und
\begin{align*}
             \begin{array} {ccc}
              \C &:\A \times \N  \rightarrow  \N \\
             \D &: \N\rightarrow\A \times \N\\
              \end{array}
\end{align*}
die zugehörigen Kodierungs- und Dekodierungsfunktionen. Dabei liefert die Kodierungsfunktion $ \C$ für $s\in\A$ und $x\in \N$  den verschlüsselten Wert $x^{'} = \mathcal C(s,x)$ und $\D$ bezeichnet die Inverse von $\C$:
\begin{align*}
\D \circ \C  \left( b, \C(a,x)\right)  = (b, \C(a,x))
\end{align*}
Nach Konstruktion verhält sich $x$ wie ein Stack: Der letzte verschlüsselte Wert ist der erste, den die Dekodierungsfunktion liefert. Nachdem $\C$ für wachsendes $x$ über alle Grenzen wächst, muss $x$ auf ein Intervall mit festen Grenzen eingeschränkt werden: Hierfür wird in \cite{Duda} das sog. "`normalisierte Intervall"' 
\begin{align*}
I(L,b):=\{L,L+1,\ldots,b\cdot L-1\}
\end{align*}
für beliebiges $L \in \N$ und $b\in \N, b\geq 2$ definiert, wobei $b$ die Basis des Kodierungsverfahrens bezeichnet. Ferner muss gewährleistet sein, dass für $x^{'} = \C(s,x)$  und $(s,y) = \D(y^{'})$ stets $(x^{'}, y) \in I\times I$ gilt. Hierfür wird in \cite{Krajcevski} folgende Konvention getroffen:
\begin{flushleft}
1)\;Sei  $x^{'} > b\cdot L -1$. Ersetze $x^{'}$ solange durch  $\left\lfloor \frac{x^{'}}{b}  \right\rfloor$  bis $x^{'} \in I$
\\
2)\;Sei  $x^{'} <L$. Ersetze $x^{'}$ solange durch  $x^{'} \cdot b$  bis $x^{'} \in I$
\end{flushleft}
Im allgemeinen funktioniert dieser Ansatz nicht, aber es kann folgendes gezeigt werden:
\\
Sind die "`Index-Mengen"' 
\begin{align*}
I_{s} := \left\{ x\;|\; \C(s,x) \in I  \right\}
\end{align*} 
von der Form $I_s = \left\{k,k+1,\ldots,b\cdot k -1\right\},\, k\geq 1$ (eine Eigenschaft, die Duda in \cite{Duda} als "`b-Eindeutigkeit"' bezeichnet), dann sind die Algorithmen synchron. 
\subsection{Einführendes Beispiel: Uniform binary variant streaming  ({\tt{uabs}})}
Vorab lässt sich das Verfahren folgendermaßen beschreiben:
\\
\begin{center}
\begin{tabular}{c|c}
Verschlüsselung & Entschlüsselung
\\
\hline
PROCEDURE ENCODE(x, buffer) & FUNCTION DECODE(buffer)
\\
{\tt{WHILE}} $\C(x,s) \not\in I_{s}$ do &  $(s,x) \leftarrow D(x)$
\\
buffer.save(x\,\text{mod}\,b)& {\tt{WHILE}} $x \not\in I$ do
\\
$x \leftarrow \left\lfloor x / b \right\rfloor$ & $x\leftarrow b\cdot x + \text{buffer.read()}$
\\
{\tt{END {\tt{WHILE}}}} & {\tt{END {\tt{WHILE}}}}
\\
$x\leftarrow \C(x,s) $  & {\tt{return}} s
\\
END PROCEDURE & END FUNCTION
\end{tabular}
\end{center}
Einführend wird das in \cite{Giesen} angebene Beispiel betrachtet:
\begin{Beispiel}
Sei z.B. "`babba"' eine auf dem zwei-Symbol Alphabet  $\A :=\left\{a, b\right\}$  mit $p_a=1 /4, p_b = 3/4$ bestehende Nachricht und
\begin{align*}
\C(a,x) =4 x,\quad
\C(b,x) = 4 \left\lfloor x/3 \right\rfloor + \left(x\,\text{mod}\, 3\right)+ 1.
\end{align*}
Für $b=2$ und $L=16$, d.h. $I(L,b)=\{16,17,\ldots,31\}$ berechnet man die den Symbolen korrespondierenden $b$-eindeutigen Index-Mengen:
\par
\vspace{0.5cm}
\begin{center}
 \begin{tabular}{l|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c}
 & 16 & 17 & 18 & 19 & 20 & 21 & 22 & 23 & 24 & 25 & 26 & 27 & 28 & 29 & 30 &31\\
\hline
a	& 4 & & & & 5	& &  & & 6 & &  & & 7 & & &	\\
\hline
b	&  & 12 & 13 & 14 & 	& 15 & 16 & 17 &  & 18 & 19 & 20 &  & 21 & 22 & 23 	\\
\end{tabular}
\end{center}
\vspace{0.5cm}
Als Dekodierungsfunktion erhält man:
$$
\D(x):
               \begin{cases}
                 \left(a,x / 4\right)          & \text{falls}\,\, x \equiv 0 \,\text{mod}\, 4,\\
                   \left(b,3 \left\lfloor x/4\right\rfloor + \left(x\,\text{mod}\, 4\right)- 1 \right) & \text{sonst}.
                \end{cases}
$$
Wird $u\in\A$ mit $\C$ codiert wächst $x$ um den Faktor $1 / p_u$.
Die Prozedur der Verschlüsselung und Entschlüsselung lässt sich nachfolgender Tabelle entnehmen:
\begin{center}
{\color{gray!50!blue}\rule{8cm}{0.5mm}}
\\
\begin{tabular}{c c c}
Kodierer & x & Dekodierer
\end{tabular}
\vspace{-0.2cm}
\\
{\color{gray!50!blue}\rule{8cm}{0.1mm}}
\\
\begin{tabular}{c c c}
finaler Zustand & & finaler Zustand
\\
$\uparrow$ & 19 & $\downarrow$
\\
encode 'b' & & decode 'b'
\\
$\uparrow$ & 14 & $\downarrow$
\\
$x \not\in I_{b}$; save(0) &  &$x\not\in I(L,b)$; read()=0;
\\
$\uparrow$ & 28 & $\downarrow$
\\
encode 'a' & & decode 'a'
\\
$\uparrow$ & 7 & $\downarrow$
\\
$x \not\in I_{a}$; save(1) &  &$x\not\in I(L,b)$; read()=1;
\\
$\uparrow$ & 15 & $\downarrow$
\\
$x \not\in I_{a}$; save(0) &  &$x\not\in I(L,b)$; read()=0;
\\
$\uparrow$ & 30 & $\downarrow$
\\
encode 'b' & & decode 'b'
\\
$\uparrow$ & 22 & $\downarrow$
\\
encode 'b' & & decode 'b'
\\
$\uparrow$ & 16 & $\downarrow$
\\
encode 'a' & & decode 'a'
\\
$\uparrow$ & 4 & $\downarrow$
\\
$x \not\in I_{a}$; save(0) &  & $x\not\in I(L,b)$; read()=0;
\\
$\uparrow$ & 8 & $\downarrow$
\\
x $\not\in I_{a}$; save(0) &  & $x\not\in I(L,b)$; read()=0;
\end{tabular}
\end{center}
\begin{center}
\begin{tabular}{c c c}
Kodierer & x & Dekodierer
\end{tabular}
\vspace{-0.2cm}
\\
{\color{gray!50!blue}\rule{8cm}{0.1mm}}
\\
\begin{tabular}{c c c}
$\uparrow$ & 16  & $\downarrow$
\\
initialer Zustand & & lesen beendet
\end{tabular}
\\
{\color{gray!50!red}\rule{8cm}{0.1mm}}
\end{center}
\end{Beispiel}
\subsection{{\tt{uabs}} für n-elementige Symbolalphabete ({\tt{uans}})}
Ziel des folgenden Unterkapitels ist es das besprochene {\tt{uabs}}-Verfahren auf $n$-elementige Symbolalphabete zu verallgemeinern.
Im folgenden sei $\A$ ein $n$-elementiges Alphabet $(n > 1)$ mit zugehörigen Auftrittswahrscheinlichkeiten $\xP:=\left\{p_{i_{k}}\,|\,1\leq k \leq n-1\right\}$ wobei gilt:
\begin{align*}
\forall p_{i_{k}} \in \xP\, \exists\, i_{k}\in\N :\, p_{i_{k}}\cdot 2^{i_{k}} =1,\; \sum_{p\in\xP}p = 1.
\end{align*}
Damit lässt sich das  normalisierte Intervall in disjunkte Teilmengen zerlegen:

\begin{Hilfssatz}
Seien $a_{k}, a_{l}\in \A, k < l$ zwei Symbole mit $p_k=1 / 2^{k}$ und $p_l=1 / 2^{l}$.
Sei $0<= r_k <2^k$ und $r_l:=\min_{r\in\N}
\left\{(r_k-r)\text{mod}\,2^k \not\equiv 0\right\}$.
Folgende Mengen sind disjunkt\footnote{\footnotesize{Dieser Sachverhalt gilt für jede Primzahl.}}:

\begin{align*}
I_{a_k}:=\left\{2^k + n\cdot r_k \,\left|\right.\, n\in\N\right\},\;\;
I_{a_l}:=\left\{2^l +  n\cdot r_l\,\left|\right.\,\,n\in\N \right\}.
\end{align*}
\end{Hilfssatz}

\begin{proof}
Sei $\mu\in\N$ mit $\mu\in I_{a_k}\cap I_{a_l}$. Dann existieren $s,t \in\N$ mit
\begin{align*}
 s\cdot 2^k + r_k =t \cdot 2^l +  r_l\qquad \Leftrightarrow\qquad 2^k\cdot \left(s - t\cdot 2^{l-k}\right) = r_l - r_k.
\end{align*}
Hieraus folgt sofort der Widerspruch $(r_l-r_k)\text{mod}\,2^k \equiv 0$, also $I_{a_{k}}= I_{a_{l}}$.
\end{proof}
Folgender Algorithmus liefert arithmetische Progressionen zur Zerlegung von $I(L,b)$ in disjunkte Teilmengen: 
\begin{Algorithmus}
\begin{itemize}
\item[1] Fasse Symbole mit gleicher Wahrscheinlichkeit zusammen.
\item[2] Sortiere Zusammenfassung nach fallender Wahrscheinlichkeit.
\item[3] Für Wahrscheinlichkeit $p_{i_{k}}$ existieren die Moduloreste	$R_{i_{k}}:=\left\{0, 1, 2, \ldots, 2^{i_{k}}-1\right\}$.
\item[4] Beginne bei $k=0$.
\item[5] Sei $k<l <=N-1$. Korrespondiert $p_{i_{k}}$ zu $t\in\N$ Symbolen, selektiere die ersten $t$ Reste aus $R_{i_{k}}$  zu $R_{i_{k}}^{'} \subseteq R_{k}$. Entferne $x \in R_{i_{l}}$ falls ein $y\in R_{i_{k}}^{'}$ existiert mit $0 \equiv (x-y)\text{mod}\,2^{i_{k}}.$
\item[6] Setze $k=k+1$ und gehe zu Schritt 5.
\end{itemize}
\end{Algorithmus}


\begin{Beispiel}
Für die Demonstration eines konkreten Beispiels wird die auf dem drei-Symbol Alphabet  $\A :=\left\{a, b, c\right\}$    mit $p_a=1 /2, p_b = 1/4, p_c = 1/4$ bestehende Nachricht "`abbac"' für $b=2,\;L=16$ kodiert und dekodiert. Algorithmus 4.3.1 liefert die disjunkten aritmetischen Progressionen:

\begin{align*}
\begin{tabular}{c|c|c}
$x\in \A$ & $p_{i_{k}}\in \xP$ & $R_{i_{k}}$
\\
\hline
a & 1/2 & $\left\{0, 1\right\}$
\\
\hline
b & 1/4 & $\left\{0, 1,2 ,3\right\}$
\\
\hline
c & 1/4 & $\left\{0, 1,2 ,3\right\}$
\end{tabular}
&\quad \stackrel{3}{\Rightarrow} 
\begin{tabular}{c|c|c}
a & 1/2 & $\left\{\textcolor{blue}{0}\right\}$
\\
\hline
b, c & 1/4 & $\left\{0, 1,2,3\right\}$
\end{tabular}
\quad \stackrel{4}{\Rightarrow}
\begin{tabular}{c|c|c}
a & 1/2 & $\left\{\textcolor{blue}{0}\right\}$ 
\\
\hline
b, c & 1/4 & $\left\{\not{\textcolor{blue}{0}},1 , \not{\textcolor{blue}{2}},3\right\}$
\end{tabular}
\\
&\quad \stackrel{5}{\Rightarrow}
\begin{tabular}{c|c|c}
$a$ & 1/2 & $\left\{0\right\}$ 
\\
\hline
$b, c$ & 1/4 & $\left\{1,3\right\}$ 
\end{tabular}
\end{align*}

Als Kodierungsfunktion erhält man nun
\begin{align*}
\C(a,x)=2 x,\quad
\C(b,x) = 4 x + 1,\quad
\C(c,x) = 4 x + 3,
\end{align*}
also die den Symbolen korrespondierenden $b$-eindeutigen Index-Mengen:
\par
\vspace{0.5cm}
\begin{center}
 \begin{tabular}{l|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c}
 & 16 & 17 & 18 & 19 & 20 & 21 & 22 & 23 & 24 & 25 & 26 & 27 & 28 & 29 & 30 &31\\
\hline
a	& \centering 8 & & 9 & & 10	& & 11 & & 12 & & 13 & & 14 & & 15 &	\\
\hline
b	&  & 4 &  & & 	& 5 &  & &  & 6 &  & &  & 7 & 	\\
\hline
c	&  & &  & 4& 	&  &  &  5&  &  &  & 6 &  &  & & 7 	\\
\end{tabular}
\end{center}
\vspace{0.5cm}
Durch Invertierung erhält man sofort die zugehörige Dekodierungsfunktion:
$$
\D(x):
               \begin{cases}
                 \left(a,x / 2 \right)         & \text{für}\,\, x \equiv 0 \,\text{mod}\, 2,\\
                    \left(b,(x-1)/ 4\right)           & \text{für}\,\, x \equiv 1 \,\text{mod}\, 4\\
									\left(c, (x-3)/ 4 \right)          & \text{für}\,\, x \equiv 3 \,\text{mod}\, 4\\
                \end{cases}
$$

Die Prozedur der Verschlüsselung und Entschlüsselung lässt sich nachfolgender Tabelle entnehmen:
\begin{center}
{\color{gray!50!blue}\rule{8cm}{0.5mm}}
\\
\begin{tabular}{c c c}
Kodierer & x & Dekodierer
\end{tabular}
\vspace{-0.2cm}
\\
{\color{gray!50!blue}\rule{8cm}{0.1mm}}
\\
\begin{tabular}{c c c}
finaler Zustand & & finaler Zustand
\\
$\uparrow$ & 16 & $\downarrow$
\\
encode 'a' & & decode 'a'
\\
$\uparrow$ & 8 & $\downarrow$
\\
$x \not\in I_{a}$; save(1) &  & $x\not\in I(L,b)$; read()=1;
\\
$\uparrow$ & 17 & $\downarrow$
\\
encode 'b' & & decode 'b'
\\
$\uparrow$ & 4 & $\downarrow$ 
\\
$x \not\in I_{b}$; save(0) &  & $x\not\in I(L,b)$; read()=0;
\\
$\uparrow$ & 8 & $\downarrow$
\\
$x \not\in I_{b}$; save(1) &  &$x\not\in I(L,b)$; read()=1;
\\
$\uparrow$ & 17 & $\downarrow$
\\
encode 'b' & & decode 'b'
\\
$\uparrow$ & 4 & $\downarrow$
\\
$x \not\in I_{b}$; save(1) &  &$x\not\in I(L,b)$; read()=1;
\\
$\uparrow$ & 9 & $\downarrow$
\\
$x \not\in I_{b}$; save(0) &  &$x\not\in I(L,b)$; read()=0;
\\
$\uparrow$ & 18 & $\downarrow$
\\
encode 'a' & & decode 'b'
\\
$\uparrow$ & 9 & $\downarrow$
\\
$x \not\in I_{a}$; save(1) &  & $x\not\in I(L,b)$; read()=1;
\\
$\uparrow$ & 19 & $\downarrow$
\\
encode 'c' & & decode 'c'
\\
$\uparrow$ & 4 & $\downarrow$
\\
$x \not\in I_{c}$; save(0) &  & $x\not\in I(L,b)$; read()=0;
\\
$\uparrow$ & 8 & $\downarrow$
\\
x $\not\in I_{c}$; save(0) &  & $x\not\in I(L,b)$; read()=0;
\\
$\uparrow$ & 16  & $\downarrow$
\\
initialer Zustand & & lesen beendet
\end{tabular}
\\
{\color{gray!50!red}\rule{8cm}{0.1mm}}
\end{center}
\end{Beispiel}

Für das Wachstumsverhalten der Entropie erhalten wir:
\begin{Hilfssatz}
Sei $\A$ ein $N$ elementiges Symbolalphabet mit zugehörigen Auftrittswahrscheinlichkeiten $\left(\frac{1}{2}\right)^{i_{k}}$ und $k+k_{0}\geq\frac{2^{i_k}}{i_k} \geq k$ für alle $k$ und $k_{0}\in\N$, dann ist $H(\A)-H_{0}$ beschränkt.
\end{Hilfssatz}
\begin{proof}
\begin{align*}
H(\A) - H_{0} =-\sum_{k=1}^{N-1}\frac{1}{2}^{i_{k}} \text{log}_{2}\frac{1}{2}^{i_{k}} - \text{log}_{2}(N-1)
= \sum_{k=1}^{N-1}i_{k}\cdot \frac{1}{2}^{i_{k}} - \frac{\text{log}(N-1)}{\text{log}(2)}.
\end{align*}
Damit folgt:
\begin{align*}
\sum_{k=1}^{N-1}\frac{1}{k+k_{0}} - \frac{\text{log}(N-1)}{\text{log}(2)} \leq H(\A) - H_{0} &\leq \sum_{k=1}^{N-1} \frac{1}{k+1} - \frac{\text{log}(N-1)}{\text{log}(2)}
\\
& <  \sum_{k=1}^{N} \frac{1}{k} - \text{log}(N-1) .
\end{align*}
Wir betrachten nur die obere Reihe, die Schlussfolgerung für die untere Reihe ist analog:
\par
Die Folge 
\begin{align*}
\gamma_{n}:= \sum_{k=1}^{N} \frac{1}{k} - \text{log}(N) 
\end{align*}
ist monoton fallend und nach unten beschränkt:
\begin{align*}
\gamma_{n+1}-\gamma_{n} &= \frac{1}{N+1} - \left(\text{log}(N+1) - \text{log}(N)\right) 
\\
& = \frac{1}{N+1} - \text{log}\left(1+\frac{1}{N}\right)
\end{align*}
Da für alle $x > 0$ log$(x) \geq \frac{x-1}{x}$ gilt, folgt:
\begin{align*}
\gamma_{n+1}-\gamma_{n} \leq \frac{1}{N+1} - \frac{\frac{1}{N}}{1+\frac{1}{N}} = \frac{1}{N+1} - \frac{1}{N+1} = 0.
\end{align*}
Also ist $\gamma_n$ monoton fallend.
Da für alle $x>-1$ gilt $\text{log}(x+1)\leq x$ folgt
\begin{align*}
\gamma_{n} &= \sum_{k=1}^{N}\frac{1}{k} -\text{log}\left(\prod_{k=1}^{N-1}\frac{k+1}{k}\right) = \sum_{k=1}^{N}\frac{1}{k} - \sum_{k=1}^{N-1}\text{log}\left(\frac{k+1}{k}\right) 
\\
&\geq \sum_{k=1}^{N}\frac{1}{k} -  \sum_{k=1}^{N-1}\frac{1}{k} > 0.
\end{align*}
\end{proof}
\subsection{Range variants and streaming: ({\tt{rans}})}
In diesem Abschnitt betrachten das in \cite{Krajcevski} angegebene Verfahren, welches ohne die Benutzung der in der {\tt{uabs}} verwendeten Index-Mengen auskommt und die Auftrittswahrscheinlichkeiten der einzelnen Symbole nicht approximieren muss:
\par
Sei $F_{s}$ die Häufigkeit des Symbols $s\in\A$ und $M:=\sum_{s\in\A}F_{s}$.
\begin{align*}
\C(s,x)&= x^{'} := M \cdot \left\lfloor x / F_{s}  \right\rfloor + B_{s} + \left(x\,\text{mod}\,F_{s}\right)
\\
\D(x^{'}) &=(s, x):=\left(\xL(\R),   F_{s}\cdot\left\lfloor x^{'} / M \right\rfloor    + \R - B_{s}\right)
\end{align*} 
wobei
\begin{align*}
\R := x^{'}\,\text{mod}\,M, \quad B_{s}:=\sum_{i=0}^{s-1} F_{s},
\quad
\xL(z):= \max_{B_{s} \leq z} s .
\end{align*}
Die Funktion $\xL$ determiniert dabei das Symbol.
$\C$ und $\D$ sind invers:
\begin{align*}
\D \circ \C(s, x)&=\left(\xL(\R),F_{s}\cdot \left\lfloor   1 / M \left( 
M\cdot \left\lfloor  x / F_{s}\right\rfloor  + B_{s}   +  \left(x\,\text{mod}\,F_{s}\right)
\right)  \right\rfloor    + \R - B_{s}\right)
\\
&=
\left(\xL(\R),F_{s}\cdot \left\lfloor 
\left\lfloor  x / F_{s}\right\rfloor  + \frac{B_{s}   +  \left(x\,\text{mod}\,F_{s}\right)}{M}
\right\rfloor  + \R - B_{s} \right).
\end{align*}
Wegen 
\begin{align*}
\frac{B_{s}   +  \left(x\,\text{mod}\,F_{s}\right)}{M} \leq \frac{B_{s}   +  F_{s}-1}{M} = \frac{B_{s+1}-1}{M} < 1
\end{align*}
folgt
\begin{align*}
\D \circ \C(s, x)&=
\left(\xL(\R),F_{s}\cdot
\left\lfloor  x / F_{s}\right\rfloor  + \R - B_{s} \right)
\\
\end{align*}
Mit $\R = x^{'}\,\text{mod}\,M = B_{s} + \left(x\,\text{mod}\,F_{s}\right)$
erhält man
\begin{align*}
\D \circ \C(s, x)&=
\left(\xL(\R),F_{s}\cdot
\left\lfloor  x / F_{s}\right\rfloor  + \left(x\,\text{mod}\,F_{s}\right) \right)
\\
&=
\left(\xL(\R),F_{s}\cdot
\left(\frac{x - \left(x\,\text{mod}\,F_{s}\right)}{F_{s}}\right) + \left(x\,\text{mod}\,F_{s}\right) \right)
\\
&=\left(\xL(\R),x\right)
\end{align*}
Abschließend folgt:
\begin{align*}
\xL(\R) = \xL\left(x^{'}\,\text{mod}\,M\right)= \xL(B_{s} + x\,\text{mod}\,F_{s})= \max_{0\leq x\,\text{mod}\,F_{s}} s = s.
\end{align*}
Das Verfahren lässt sich folgendermaßen beschreiben:
\begin{center}
\begin{tabular}{c|c}
Verschlüsselung & Entschlüsselung
\\
\hline
PROCEDURE ENCODE(x, List) & FUNCTION DECODE(List)
\\
new buffer & buffer = List.get()
\\
{\tt{WHILE}} $\C(x,s) \not\in I$ do &  $(s,x) \leftarrow D(x)$
\\
buffer.save(x\,\text{mod}\,b)&  $x\leftarrow b\cdot x + \text{buffer.read()}$
\\
$x \leftarrow \left\lfloor x / b \right\rfloor$ &  {\tt{return}} s
\\
{\tt{END {\tt{WHILE}}}} & END FUNCTION
\\
List.add(buffer)
\\
$x\leftarrow \C(x,s) $  &
\\
END PROCEDURE & 
\end{tabular}
\end{center}
\begin{Beispiel}
Zur Demonstration eines konkreten Beispiel wird wieder die auf dem  3-Symbol-Alphabet $\A:=\{a, b, c\}$ mit den Häufigkeiten $F_{a}:=11, F_{b}:=3,  F_{c}:=2$ bestehende Nachricht "`abbac"' betrachtet:
\par
\vspace{0.5cm}
Es gilt dann $M=16$ und man erhält folgende Lookup-Tabelle:
\begin{center}
\begin{tabular}{c|c|c|c}
$x$ & $<11$ & $11 \leq x <14$ & $14\leq x$
\\
\hline
Symbol & a & b & c
\end{tabular}
\end{center}
\begin{center}
{\color{gray!50!blue}\rule{8cm}{0.5mm}}
\\
\begin{tabular}{c c c}
Kodierer & x & Dekodierer
\end{tabular}
\vspace{-0.2cm}
\\
{\color{gray!50!blue}\rule{8cm}{0.1mm}}
\\
\begin{tabular}{c c c}
finaler Zustand & & finaler Zustand
\\
$\uparrow$ & 26 & $\downarrow$
\\
encode 'a' & & decode 'a'
\\
$\uparrow$ & 21 & $\downarrow$
\\
$x \not\in I(L,b)$; save(1) &  & read()=1;
\\
$\uparrow$ & 43 & $\downarrow$
\\
$x \not\in I(L,b)$; save(0) &  & read()=0;
\\
$\uparrow$ & 86 & $\downarrow$
\\
$x \not\in I(L,b)$; save(0) &  & read()=0;
\\
$\uparrow$ & 172 & $\downarrow$
\\
encode 'b' & & decode 'b'
\\
$\uparrow$ & 31 & $\downarrow$
\\
$x \not\in I(L,b)$; save(0) &  & read()=0;
\\
$\uparrow$ & 62 & $\downarrow$
\\
$x \not\in I(L,b)$; save(0) &  & read()=0;
\\
$\uparrow$ & 124 & $\downarrow$
\\
encode 'b' & & decode 'b'
\\
$\uparrow$ & 22 & $\downarrow$
\\
encode 'a' & & decode 'a'
\\
$\uparrow$ & 17 & $\downarrow$
\\
$x \not\in I(L,b)$; save(1) &  &  read()=1;
\\
$\uparrow$ & 35 & $\downarrow$
\\
$x \not\in I(L,b)$; save(1) &  & read()=1;
\\
$\uparrow$ & 71 & $\downarrow$
\\
$x \not\in I(L,b)$; save(0) &  &  read()=0;
\\
$\uparrow$ & 142 & $\downarrow$
\\
encode 'c' & & decode 'c'
\\
$\uparrow$ & 16  & $\downarrow$
\\
initialer Zustand & & lesen beendet
\end{tabular}
\\
{\color{gray!50!red}\rule{8cm}{0.1mm}}
\end{center}
\end{Beispiel}
\subsection{Vergleich der beiden Verfahren}\label{vglBeiderVerfahren}
Das {\tt{rans}}-Verfahren stellt keine Bedingungen an die Werte der Auftrittswahrscheinlichkeiten oder die Wahl des normalisierten Intervalls, außerdem ist das Verfahren sehr leicht zu implementieren.
\par
Die Generierung der benötigten Indexmengen für das {\tt{uans}}-Verfahren ist sehr aufwendig und auch nur durch Approximation der Auftrittswahrscheinlichkeiten möglich. Außerdem
muss das normalisierte Intervall so gewählt werden, dass jedes Symbol mindestens einen Repräsentanten innerhalb  des normalisierten Intervalls besitzt:
\par
Sei z.B. $L=2$ und $b=3$, $\A:=\left\{a, b, c, d\right\}$ mit $p_{a}=1/2$, $p_{b}=1/4$ und $p_{c}=p_{d}=1/8$. 
Dann gilt:
\begin{align*}
I_{a}=\left\{1,2\right\},\quad  I_{b}=\left\{1\right\},\quad I_{c}&=\left\{1\right\},\quad I_{d}=\varnothing.
\end{align*}
\par
Wählt man $L^{*}$ derart, dass 
\begin{align*}
L^{*} = \max \left\{r_{k}\,|\,r_{k}\in R_{i_{k}}, 0\leq i_{k} < N-1\right\} +1
\end{align*} 
dann gilt für alle Reste $0 \leq r_{k} < L^{*}$. Verschiebt man dieses Intervall noch um die größte auftretende Potenz von zwei (=:M), so besitzt jede Indexmenge einen Repräsentanten im Intervall $[M,M + L^{*}-1]$, also auch in $I(b,L)$ für $b=2$ und $L:=M$ $($da $L^{*} \leq M)$, also gilt für die korrespondierenden Indexmengen $I_{i_{k}} \neq \varnothing$.
\par
Eine weiterer Nachteil findet sich in dem Umstand, dass {\tt{uans}}-Verfahren nicht immer terminiert:
\par
Sei z.B. $b=4$ und $L=16$ und $\alpha$ ein Symbol mit der relativen Häufigkeit $p_{\alpha}=1/32$. Angenommen Algorithmus 4.3.1 liefert einen Modulorest $0 < r < 16$, dann erhält man als zugehörige Indexmenge $I_{\alpha}=\{1\}$. Falls der Kodiererer z.B. bei  $x=48$ das Symbol $\alpha$ liest, so teilt er so lange durch $b$ bis er einen Wert aus $I_{\alpha}$ erhält, was nie der Fall ist.
\par
Zusammenfassend ist das {\tt{rans}}-Verfahren damit flexibler. 
\par
Im Falle der Terminierung liefert das {\tt{uans}}-Verfahren  aber die bessere Kompressionsrate:
\begin{Beispiel}
Man betrachte die Komprimierung des Wortes $\mathcal{T}$:="`MISSISSIPPI"'  für $b=2$, $L=16$, $M=8$ durch beide Verfahren:
\par
\vspace{0.5cm}
\begin{minipage}[h]{.5\textwidth}
$\mathcal{T}\stackrel{{\tt{uans}}}{\mapsto} 0010000010010110010110\;19$
\end{minipage}
\hfill
 \begin{minipage}[h]{.5\textwidth}
$\mathcal{T}\stackrel{{\tt{rans}}}{\mapsto} 1|01|100|1|110|00|0|00|1|0010|19$
\end{minipage}   
\vspace{0.5cm}
\\
Das {\tt{rans}}-Verfahren benötigt zur Dekomprimierung von $\mathcal{T}$ zusätzliche Information. Der Grund diese Umstandes liegt in der Konstruktion: Das {\tt{rans}}-Verfahren normalisiert nur bei der Kodierung aus positiver Richtung in das "`normalisierte Interval"' $I(L,b)$, während das {\tt{uans}}-Verfahren das Bitmuster so lange ausliest und den augenblicklichen Wert erhöht, bis ein Wert größer als $L$ gefunden ist.
\end{Beispiel}

\subsection{Vergleich zu Huffmann und Arithmetischem Kodieren}
Der Huffmann-Algorithmus kodiert jedes Symbol einzeln, während der erweiterte Huffman-Algorithmus zu einer gegebenen Länge jede erdenkliche Folge einzeln verschlüsselt. Der Vorteil der Erweiterung liegt darin, dass sich ein anfänglich nicht zu komprimierender Code doch komprimieren lässt. Allerdings ist die Codierung ab einer bestimmten Länge kaum realisierbar. Dieses Problem tritt bei der Verwendung von asymmetrischen Zahlensystemen nicht auf.

\newpage
\section{Anwendung auf Bilddateien}
In diesem Abschnitt werden die beiden in Kapitel ~\ref{ANS} besprochenen Verfahren auf Bilddateien angewendet, d.h. im Folgenden gilt $\A=\{0,1,\ldots,255\}$.  
\subsection{Bestimmung der Häufigkeiten}
Zum Laden einer Bilddatei wird die Funktion \footnote{Hierfür wird die unter \cite{Barret} zu Verfügung gestellte Bibliothek verwendet.} 
\begin{verbatim}
stbi_load(char const *filename, int *x, int *y, int *comp, int req_comp)
\end{verbatim}
 welche einen Zeiger auf ein Array vom Typ {\tt{unsigned char}} liefert, verwendet.
Die Ermittlung der Häufigkeiten $F_{s},\;s\in\A$  erfolgt dann durch Iteration über dieses Array\footnote{Die Bestimmung der Häufigkeiten erfolgt parallel, bei der Programmierung der parallelen Algorithmen orientiert sich der Autor an \cite{Williams}.} während derer die jeweiligen Einträge eines {\tt{std::vector<uint32>}} der Größe 256 inkrementiert werden.
\subsection{Normalisierung}
Wesentliche Voraussetzung für die Anwendung der beiden Verfahren ist eine Normalisierung der Häufigkeiten $F_{s}\;s\in\A$ welche Gegenstand der beiden folgenden Unterabschnitte ist.

\subsubsection{Normalisierung der Häufigkeiten des {\tt{uans}}-Verfahrens}

Zunächst wird die Summe aller Häufigkeiten und jede auftretende Häufigkeit durch eine Potenz von zwei approximiert:
\par

\begin{center}
\begin{tabular}{l | l}
FUNCTION NEARESTPO2({\tt{uint32 x}}) & FUNCTION NORMALIZE() 
\\
$u=2$; $b=1$;  & y = NEARESTPO2(SUM); 
\\
{\tt{WHILE}}$({\tt{x}} > 1)$ ${\tt{x}} >>= 1;$ $u <<= 1;$ & {\tt{WHILE}}((S=getSUM()) != y) 
\\
{\tt{END {\tt{WHILE}}}} & {\tt{IF}}(S > y)
\\
b = u >> 1;   & MAX = getMaximalFrequency() >> 1;
\\
{\tt{return}} u-{\tt{x}} > {\tt{x}} - b ? b : u; & {\tt{ELSE}}
\\
END FUNCTION & MIN = getMinimalFrequency() << 1;
\\
& {\tt{END WHILE}}
\\
& END FUNCTION
\end{tabular} 
\end{center}

Anschließend müssen die Häufigkeiten derart verändert werden, dass ihre Summe mit der Approximation der ursprünglichen Summe wieder übereinstimmt. Aus Gründen der Performanz und der Konsistenz werden hierbei nur echt positive Häufigkeiten berücksichtigt: Solange die Summe der Häufigkeiten nicht mit der Approximation der Summe übereinstimmt, wird je nach Wert der Approximation die maximale Häufigkeit (MAX) halbiert oder die minimale Häufigkeit (MIN) verdoppelt.   
 
\subsubsection{Normalisierung der Häufigkeiten des {\tt{rans}}-Verfahrens}
Wie in \cite{Krajcevski} vorgeschlagen, werden die Häufigkeiten zunächst derart skaliert, dass für ihre Summe $M= 2^{11}$ gilt. 
Die Normalisierung erfolgt analog zur Normalisierung des {\tt{uans}}-Verfahren, hierbei werden nur der Rechts- bzw. Linksshift durch eine Dekrementierung bzw. Inkrementierung durch eins ersetzt.


\subsection{Wahl des normalisierten Intervalls}
Für beide Verfahren werden unterschiedliche Intervalle gewählt. Für das {\tt{rans}}-Verfahren erfolgt die feste Wahl von $b= 2^{16}$ und $L=2^{16}$ wie unter \cite{Duda1} empfohlen, während bei dem {\tt{uans}}-Verfahren $b=2$ gewählt wird und $L$ abhängig von Approximation der Summe der Häufigkeiten ist, also erst zur Laufzeit (vgl. ~\ref{vglBeiderVerfahren}) bestimmt wird.\footnote{Auch hier ist eine Skalierung wie bei der Umsetzung des {\tt{rans}}-Verfahrens möglich.} 

\subsection{Indexmengenbildung des {\tt{uans}}-Verfahren}
Wie bereits besprochen basiert das Verfahren auf der Generierung von 
Indexmengen. Hierfür müssen zunächst Symbole mit gleicher Häufigkeit 
zusammengefasst werden. Hierfür empfiehlt sich folgender Datentyp:

\begin{verbatim}
struct SymbolsWithSameFrequency
	{
		uint32 Fs;//the frequency
		std::vector<Symbol> m_Symbols;
		std::vector<uint32> m_ModuloRests;
		//....
	};
\end{verbatim}

In der Implementierung wird der die Moduloreste enthaltende {\tt{std::vector<uint32>}} vorinitialisiert, also z.B mit $0,1,2,\ldots,2^{m}-1$ für die 
Häufigkeit $F_{s}=2^m$.
Anschließend werden die Indexmengen gemäß Algorithmus 4.3.1 generiert: 
\par
Zunächst werden alle ermittelten {\tt{SymbolsWithSameFrequency}}  nach 
wachsender Häufigkeit sortiert: $S_{0},S_{1},S_{2}\ldots$.
\par
Angenommen $S_{i}$ 
verfügt über $n_{i}$ Symbole und die Häufigkeit $F_{i}$, dann werden $n_{i}$ 
Moduloreste $r_{n_{i}}$ gewählt und mit diesen Datentypen der Form
\begin{verbatim}
class IndexSubset
{
private:
	uint32 m_Frequency;
	uint32 m_ModuloRest;
	Symbol m_Symbol;
	std::vector<uint32> m_Indices;
	\\...
};
\end{verbatim} 

initialisiert. Die Indizes werden anschließend durch Auswertung der generierten 
arithmetischen Progression bestimmt. 
Für $j> i$ werden dann sämtliche Moduloreste  $r_{n_{j}}$ aus $S_{j}$ 
entfernt für die gilt 
\begin{align*}
r_{n_{j}} - r_{n_{i}} \equiv 0\;\text{mod}\;F_{i}.
\end{align*}

\subsection{Iterationswege der Kompressoren}
\begin{minipage}[h]{.5\textwidth}
Bei der Iteration über die Bilddatei stehen den Kompressoren drei mögliche Wege zur Parallelverarbeitung zu Verfügung: Zeilen-, spalten- und kanalweise. Nebenstehende Abbildung zeigt die zeilenweise Iteration: Die Kompressoren $\mathcal{C}^{i}$ und die Dekompressoren $\mathcal{D}^{i}$ kodieren bzw. dekodieren die $i$-ten Pixelzeile parallel. Zunächst wurden alle drei Iterationswege implementiert, allerdings erwies sich die Wahl des Weges als unerheblich und wurde bei Tests nur zur Überprüfung der Stabilität benutzt. Die Iteration des Kompressors in der Implementierung erfolgt stets zeilenweise.
\end{minipage}
\hfill
\begin{minipage}[h]{.5\textwidth}
\begin{flushright}
\begin{tikzpicture}
 \draw
%    horizontal
		 (0.0,3.0) -- (4.0,3.0)
		(0.0,2.5) -- (4.0,2.5)
		(0.0,2.0) -- (4.0,2.0)
		(0.0,1.5) -- (4.0,1.5)
		(0.0,1.0) -- (4.0,1.0)
		(0.0,0.5) -- (4.0,0.5)
		(0.0,0.0) -- (4.0,0.0)
	%	vertical
		(0.0,3.0) -- (0.0,0.0)
		(0.5,3.0) -- (0.5,0.0)
		(1.0,3.0) -- (1.0,0.0)
		(1.5,3.0) -- (1.5,0.0)
		(2.0,3.0) -- (2.0,0.0)
		(2.5,3.0) -- (2.5,0.0)
		(3.0,3.0) -- (3.0,0.0)
		(3.5,3.0) -- (3.5,0.0)
		(4.0,3.0) -- (4.0,0.0)
	%	nodes for encoding
		(-0.75,2.8)node[]{$\mathcal{C}^{1}$}
		(-0.25,2.7)node[]{$\rightarrow$}
		(-0.75,2.3)node[]{$\mathcal{C}^{2}$}
			(-0.25,2.2)node[]{$\rightarrow$}
		(-0.75,1.8)node[]{$\mathcal{C}^{3}$}
			(-0.25,1.7)node[]{$\rightarrow$}
		(-0.75,1.3)node[]{$\mathcal{C}^{4}$}
			(-0.25,1.2)node[]{$\rightarrow$}
		(-0.75,0.8)node[]{$\mathcal{C}^{5}$}
			(-0.25,0.7)node[]{$\rightarrow$}
		(-0.75,0.3)node[]{$\mathcal{C}^{6}$}
			(-0.25,0.2)node[]{$\rightarrow$}
%				nodes for decoding
				(4.75,2.8)node[]{$\mathcal{D}^{1}$}
		(4.25,2.7)node[]{$\leftarrow$}
		(4.75,2.3)node[]{$\mathcal{D}^{2}$}
			(4.25,2.3)node[]{$\leftarrow$}
		(4.75, 1.8)node[]{$\mathcal{D}^{3}$}
			(4.25,1.8)node[]{$\leftarrow$}
		(4.75,1.3)node[]{$\mathcal{D}^{4}$}
			(4.25,1.3)node[]{$\leftarrow$}
		(4.75,0.8)node[]{$\mathcal{D}^{5}$}
			(4.25,0.7)node[]{$\leftarrow$}
		(4.75,0.3)node[]{$\mathcal{D}^{6}$}
			(4.25,0.2)node[]{$\leftarrow$};	
\end{tikzpicture}
\end{flushright}
\vspace{2cm}
\end{minipage}
\subsection{Beschränkung der Werte auf das normalisierte Intervall $I(L,b)$}
\subsubsection{{\tt{uans}}-Verfahrens}
Im Falle des {\tt{uans}}-Verfahrens wird an der Stelle $x\in I(L,b)$ das Symbol $\alpha$ gelesen. Falls $x\in I_{\alpha}$ ist keine Normalisierung notwendig. Andernfalls erfolgt solange ein Rechtsshift um eine Stelle bis $x\in I_{\alpha}$. Nach Konstruktion gilt dann $x^{'} = F_{\alpha} * x + r_{\alpha} \in I(L,b)$.
\subsubsection{{\tt{rans}}-Verfahrens}
Im Fall des {\tt{rans}}-Verfahrens erfolgt die Normalisierung und Denormalisierung auf das Normalisierte Intervall wie unter \cite{Giesen} empfohlen:
\begin{center}
\begin{tabular}{c|c}
Normalisierung & Denormalisierung
\\
\hline
FUNCTION NORMALIZE(x, buffer) & FUNCTION DENORMALIZE(x, buffer)
\\
{\tt{WHILE}} $\C(x,s) > L*b - 1$ {\tt{do}} &  {\tt{WHILE}} $x < L$ {\tt{do}}
\\
buffer.save(x\,\text{mod}\,b)& $x\leftarrow b\cdot x + \text{buffer.read()}$
\\
$x \leftarrow \left\lfloor x / b \right\rfloor$ & {\tt{END {\tt{WHILE}}}}
\\
{\tt{END {\tt{WHILE}}}} & END FUNCTION
\\
END FUNCTION & 
\end{tabular}
\end{center}
Nachteilig gegenüber des {\tt{uans}}-Verfahrens erwies sich hier die Notwendigkeit sich die  Anzahl der Normalisierungsschritte (i.F Normalisierungstiefe) pro gelesenem Symbol einzeln abzuspeichern. Dieser Nachteil wurde bereits in Abschnitt 4.5 angedeutet und besitzt wesentlichen Einfluss auf die Größe der Datei nach Komprimierung. Jeglicher Versuch das Programm zu konfigurieren um ein Abspeichern der Normalisierungstiefe zu umgehen resultierte in einem nicht synchronen Datenkompressionschema.  
\subsection{Endresultat der Kompression: Binäre Datei}
Die Komprimierung wird in einem binären Format festgehalten welches parallel der gelesenen Bilddatei auf Platte geschrieben wird. Hierfür werden zunächst Konfigurationsparameter wie die Dimension der Ausgangsdatei, Vorkonditionierer und Kompressor sowie wichtige Parameter wie Anzahl der Elemente des Vorkonditionerers geschrieben. Anschließend werden die normalisierten Häufigkeiten, das Ergebnis der Vorkonditionierung und die ermittelten Moduloreste geschrieben, wobei im Falle des {\tt{uans}}-Verfahrens die ermittelten bits vor dem Schreibvorgang zu {\tt{uint8}} Zahlen zusammengefasst werden. 
Im Falle des {\tt{rans}}-Verfahrens müssen zusätzlich die ermittelteten Normalisierungstiefen geschrieben werden welche ebenfalls zu {\tt{uint8}} Zahlen zusammengefasst werden.
\newpage
\section{Ergebnisse}
Im Folgenden wird der Einfluss der Normalisierung und der Filterung auf Bilder demonstriert.

\subsection{Ergebnisse der Normalisierung}
Im Folgenden wird der Einfluss der Normalisierung auf die Häufigkeiten eines Bildes (Siehe nächster Abschnitt Filtertyp {\tt{none}}) demonstriert.
Die Implementierung zur Visualisierung wurde in Java umgesetzt und steht unter \cite{Haubold} zu Verfügung.
\par
\begin{center}
\includegraphics[width=0.8\linewidth,height=0.7\textheight]{Normalization/lena_unnormalized}
\captionof{figure}{Ohne Normalisierung}
\end{center}
\begin{center}
\includegraphics[width=0.8\linewidth,height=0.7\textheight]{Normalization/lena_normalized}
\captionof{figure}{Normalisierung {\tt{rans}}}
\end{center}
\begin{center}
\includegraphics[width=0.8\linewidth,height=0.7\textheight]{Normalization/lena_normalizedPowerOfTwo}
\captionof{figure}{Normalisierung {\tt{uans}}}
\end{center}
\newpage
\subsection{Ergebnisse der Filterung}
Im Folgenden wird der Einfluss der verwendeten Filter demonstriert. Die Werte der Entropie finden sich in Tabelle 1.
\par
\begin{figure}[h]
    \centering
\begin{minipage}[h]{.45\linewidth}
\centering
\includegraphics[width=0.55\linewidth]{preconditioning/lena}
\captionof{figure}{{\tt{none}}}
\end{minipage}
\hfill
\begin{minipage}[h]{.45\linewidth}
\centering
\includegraphics[width=0.55\linewidth]{preconditioning/lena_sub}
\captionof{figure}{{\tt{sub}}}
\end{minipage}
\end{figure}

\begin{figure}[h]
    \centering
\begin{minipage}[h]{.45\linewidth}
\centering
\includegraphics[width=0.55\linewidth]{preconditioning/lena_up}
\captionof{figure}{{\tt{up}}}
\end{minipage}
\hfill
\begin{minipage}[h]{0.45\linewidth}
\centering
\includegraphics[width=0.55\linewidth]{preconditioning/lena_av2}
\captionof{figure}{{\tt{average2}}}
\end{minipage}
\end{figure}

\begin{figure}[h]
    \centering
\begin{minipage}[h]{.45\linewidth}
\centering
\includegraphics[width=0.55\linewidth]{preconditioning/lena_av3}
\captionof{figure}{{\tt{average3}}}
\end{minipage}
\hfill
\begin{minipage}[h]{0.45\linewidth}
\centering
\includegraphics[width=0.55\linewidth]{preconditioning/lena_av4}
\captionof{figure}{{\tt{average4}}}
\end{minipage}
\end{figure}

\newpage
\begin{figure}[h]
    \centering
\begin{minipage}[h]{.45\linewidth}
\centering
\includegraphics[width=0.55\linewidth]{preconditioning/lena_av5}
\captionof{figure}{{\tt{average5}}}
\end{minipage}
\hfill
\begin{minipage}[h]{0.45\linewidth}
\centering
\includegraphics[width=0.55\linewidth]{preconditioning/lena_av6}
\captionof{figure}{{\tt{average6}}}
\end{minipage}
\end{figure}

\begin{figure}[h]
    \centering
\begin{minipage}[h]{.45\linewidth}
\centering
\includegraphics[width=0.55\linewidth]{preconditioning/lena_av7}
\captionof{figure}{{\tt{average7}}}
\end{minipage}
\hfill
\begin{minipage}[h]{0.45\linewidth}
\centering
\includegraphics[width=0.55\linewidth]{preconditioning/lena_av8}
\captionof{figure}{{\tt{average8}}}
\end{minipage}
\end{figure}

\begin{figure}[h]
    \centering
\begin{minipage}[h]{.45\linewidth}
\centering
\includegraphics[width=0.55\linewidth]{preconditioning/lena_paeth}
\captionof{figure}{{\tt{paeth}}}
\end{minipage}
\hfill
\begin{minipage}[h]{0.45\linewidth}
\end{minipage}
\end{figure}

\newpage
\subsubsection{Verhalten der Entropie unter Verwendung der Filterung und Normalisierung}
Abschließend geben wir das Verhalten der Entropie unter Verwendung einer Filterung und anschließender Normalisierung - also zur Laufzeit\footnote{Die hier aufgelisteten Daten entstammen der \CC -Implementierung. } - wieder. Im Grundzustand beträgt die Entropie des betrachteten Bildes 7.766.
 Die zweite Spalte gibt den Wert der Entropie nach Verwendung eines Filters wieder, die dritte bzw. vierte Spalte dokumentiert die Entropie nach zusätzlicher Normalisierung bzgl. des verwendeten Verfahrens.
\par
\vspace{1cm}
\begin{table}[h]
\begin{center}
\begin{tabular}{c | c | c | c}
Filtertyp & nach Filterung &  {\tt{uans}} & {\tt{rans}}
\\
\hline
{\tt{none}} & 7.766 & 7.77295 & 7.8796
\\
{\tt{sub}} & 5.49393 & 5.8999 & 6.24298
\\
{\tt{up}} & 4.8265 & 5.04883 & 569749 
\\
{\tt{average2}} & 5.97444 & 6.21094 & 6.62404
\\
{\tt{average3}} & 6.12365& 6.4113 & 6.80125
\\
{\tt{average4}} & 6.3044 & 6.5791 & 6.89326
\\
{\tt{average5}} & 6.79384 & 6.93262 & 7.2642
\\
{\tt{average6}} & 6.96592 & 7.05664 & 7.40429
\\
{\tt{average7}} & 7.14682 & 7.21094 & 7.49495
\\
{\tt{average8}}& 7.21671 & 7.3125 & 7.5623
\\
{\tt{paeth}} & 4.59783 & 5.24121 & 5.38627
\end{tabular}
\caption{Werte der Entropie zur Laufzeit}
\end{center}
\end{table}
\subsection{Ergebnisse der Kompression}
In diesem Unterabschnitt wird das Verhalten der Dateigröße unter Verwendung der beiden Verfahren angegeben. Zu Beginn beträgt die Größe des betrachteten Bildes
145200 Bytes.
\begin{table}[h]
\begin{center}
\begin{tabular}{c | c | c}
Filtertyp &  {\tt{uans}} & {\tt{rans}}
\\
\hline
{\tt{none}} & 144.263& 162.851
\\
{\tt{sub}} & 102.400 & 123.737 
\\
{\tt{up}} & 90.112 & 111.921
\\
{\tt{average2}} & 110.592 &  132.109
\\
{\tt{average3}} & 114.688 & 134.987
\end{tabular}
\caption{Verhalten der Dateigröße in Bytes}
\end{center}
\end{table}

\begin{table}[h]
\begin{center}
\begin{tabular}{c | c | c}
Filtertyp &  {\tt{uans}} & {\tt{rans}}
\\
\hline
{\tt{average4}} & 118.784& 137.895
\\
{\tt{average5}} & 126.976 & 146.629
\\
{\tt{average6}} & 131.072 & 150.452
\\
{\tt{average7}} & 131.072 & 153.400
\\
{\tt{average8}}& 135.168 & 154.936
\\
{\tt{paeth}} & 86.016 & 107.149
\end{tabular}
\caption{Verhalten der Dateigröße in Bytes (Fortsetzung)}
\end{center}
\end{table}
Auffällig hierbei sind die schlechten Werte des {\tt{rans}}-Verfahren: Lediglich bei den Filtertypen 1--5 und 10 resultiert eine Anwendung des Verfahrens in einer Komprimierung während das {\tt{uans}}-Verfahren in jedem Falle die Bilddatei komprimiert.
\par
Interessant ist auch das Ergebnis unter Verwendung des {\tt{paeth}}- und des {\tt{up}}-Filters: Diese Filter liefern mit Abstand die beste Komprimierung. 
\par
\vspace{0.5cm}
Wie bereits besprochen musste im Falle des {\tt{rans}}-Verfahrens die Normalisierungstiefe abgespeichert werden um die Bilddatei wiederherstellen zu können. Dieser Umstand liefert die schlechteren Werte des Verfahrens gegenüber {\tt{uans}}. Ein Verzicht resultiert zwar in ähnlichen Zahlen, bietet aber derzeit keine Möglichkeit zur Dekomprimierung der Ausgangsdatei.
\par
\vspace{0.5cm}
Abschließend hierfür sei noch das Ergebnis der Dekomprimierung unter dieser Voraussetzung gezeigt: 
\begin{figure}[h]
    \centering
\begin{minipage}[h]{.45\linewidth}
\centering
\includegraphics[width=0.55\linewidth]{preconditioning/lena}
\captionof{figure}{Ausgangsdatei}
\end{minipage}
\hfill
\begin{minipage}[h]{0.45\linewidth}
\centering
\includegraphics[width=0.55\linewidth]{preconditioning/lena_ON}
\captionof{figure}{Ergebnis ohne Berücksichtigung der Normalisierungstiefe}
\end{minipage}
\end{figure}
\par
\vspace{1cm}
Im Falle einer Abspeicherung der Normalisierungstiefe lässt sich die Ausgangsdatei wieder erfolgreich dekomprimieren.

\newpage
\section{Kommandozeilenparameter}\label{Kommandozeilenparameter}
Abschließend wird ein Überblick über die Konfiguration der Kommandozeilenparameter für das Programm gegeben:
\par
Der entgegenzunehmende Formatstring setzt sich folgendermaßen zusammen:
\begin{center}
{\tt{Pfad}} {\tt{Vorkonditionerer}} {\tt{Kompressor}} ({\tt{-v}}) 
\end{center}
\begin{itemize}
	\item {\tt{Pfad}}: Absoluter Pfad 
	\item {\tt{Vorkonditionerer}}: $n\in \{0,\ldots, 10\}$
	\\
	Die Ganzzahlen entsprechen den in Kapitel 3 besprochenen Filtern.
	\item {\tt{Kompressor}}: $n\in\{1,2\}$
	\\
	Das {\tt{rans}}-Verfahren wird durch $n=0$ selektiert, dass {\tt{uans}}-Verfahren durch $n=1$.
	\item {\tt{-v}}:
	\\
Der geklammerte Parameter (verbosing) ist optional. Bei Konkatenation werden spezifische Größen wie Entropie, Zeitdauer und Dateigröße während der Laufzeit des Verfahrens auf der Konsole ausgegeben.
\end{itemize} 
\newpage
\section{Ausblick}
Leider war es dem Autor dieser Arbeit innerhalb des zeitlichen Rahmens nicht möglich weitere Untersuchungen hinsichtlich einer Verallgemeinerung des {\tt{paeth}}-Filters anzustellen. Nachdem dieser Filter eine hervorragende Entropiereduktion liefert, sind Untersuchungen in dieser Richtung sicher sinnvoll. Ebenso bietet eine mehrfache Anwendung der besprochenen Filter Boden für Untersuchungen über das Verhalten der Entropie. 
\par
Außerdem wäre eine Verbesserung des {\tt{rans}}-Verfahren dahingehend wünschenswert, dass auf eine Abspeicherung der Normalisierungstiefe verzichtet werden kann. Im Rahmen dieser Arbeit konnte keine Gewähr für eine Komprimierung von Bilddateien unter Verwendung des {\tt{rans}}-Verfahrens gegeben werden, während das eigenständig entwickelte {\tt{uans}}-Verfahren in jedem Fall brauchbare Ergebnisse lieferte.  
\newpage
\section{Tabellenverzeichnis}
\listoftables 
\newpage
\section{Abbildungsverzeichnis}
\listoffigures
\newpage
\section{Literaturverzeichnis}
\thispagestyle{plain}
\begin{thebibliography}{DiplRS}
\bibitem[1]{Krajcevski} Krajcevski P., Pratapa S., Manocha D. {\it GST: GPU-decodable Supercompressed Textures},  Proc. of ACM SIGGRAPH Asia, (2016).
\bibitem[2]{Giesen}  Giesen F. {\it Interleaved entropy coders},  arXiv:1402.3392 , (2014).
\bibitem[3]{Duda}  Duda J. {\it Asymmetric numeral systems: entropy coding combining speed of Huffman coding with compression rate of arithmetic coding},  CoRR, abs/1311.2540v2, (2014).
\bibitem[4]{henne} Li\'{s}kiewicz M., Fernau H. {\it Datenkompression} 
\url{ https://www.uni-trier.de/fileadmin/fb4/prof/INF/TIN/Folien/DK/script.pd}.
\bibitem[5]{Li}  Li M.,  Vit\'{a}nyi P.{\it An introduction to Kolmogorov complexity and its applications}, 2. Auflage, Springer, (1997).
\bibitem[6]{Lajmi} Lajmi L. {\it Informationstheorie und Codierung}
\url{https://www.ostfalia.de/export/sites/default/de/pws/lajmi/Lehre/Codierungstheorie/pdf/Quellencodierung_SS15.pdf}.
\bibitem[7]{Rohling} Rohling H. {\it Einführung in die Informations- und Codierungstheorie} B.G. Teubner Stuttgart, (1995).
\bibitem[8]{Huffman} Huffman D. A. {\it A method for the construction of minimum-redundancy codes} Proceedings of the I.R.E.., S. 1098-1101, (1952).
\bibitem[9]{fb} {\it Smaller and faster data compression with Zstandard} \url{https://code.facebook.com/{\tt{post}}s/1658392934479273/smaller-and-faster-data-com{\tt{pre}}ssion-with-zstandard/}
\bibitem[10]{apple}{\it Apple Open-Sources its New Compression Algorithm LZFSE} \url{https://www.infoq.com/news/2016/07/apple-lzfse-lossless-opensource}
\bibitem[11]{google}{\it Google Draco 3D compressor} \url{https://github.com/google/draco}
\bibitem[12]{png}{\it PNG (Portable Network Graphics) Specification} \url{https://www.w3.org/TR/PNG-Filters.html}
\bibitem[13]{Breymann}{Breymann U.} {\it DER C++ Programmierer}, Carl Hanser Verlag München, (2015).
\bibitem[14]{Williams}{Williams A.} {\it C++ Concurrency IN ACTION}, Manning Publications Co Shelter Island NY 11964 (2012).
\bibitem[15]{Barret}{\it stb single-file public domain libraries for C/\CC} \url{https://github.com/nothings/stb}
\bibitem[16]{Duda1}{\it Range ANS (rANS) - direct alternative for range coding}\url{https://encode.ru/threads/1870-Range-ANS-(rANS)-faster-direct-replacement-for-range-coding}
\bibitem[17]{Haubold}{\it ImageProcessor} \url{https://github.com/Hau-Bold/ImageProcessor}
\end{thebibliography}

\newpage
\begin{titlepage}
\section*{Erklärung:}
\noindent {\large Die vorliegende Bachelorarbeit wurde am Institut für Informatik  der Hochschule Coburg nach einem Thema von Herrn Prof.~Dr.~Quirin~Meyer erstellt.
\newline Hiermit versichere ich, dass ich diese Arbeit selbstständig angefertigt und dazu nur die angegebenen Quellen verwendet habe.

\vspace{1.5cm}

\noindent Coburg, den \today

\vspace{0.5cm}
\begin{flushright}
\includegraphics{Unter}
\end{flushright}
\raggedleft Michael Krasser\quad\quad \par}
\vfill
\end{titlepage}

\end{document}
